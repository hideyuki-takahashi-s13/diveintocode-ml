{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "\n",
    "$$\n",
    "N_{out} = \\frac{N_{in}+2P-F}{S}+1\n",
    "$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$S$ : ストライドのサイズ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_out_shape(n_in, fill_size, pad=0, stride=1):\n",
    "    n_out = (n_in + 2*pad - fill_size) / stride + 1\n",
    "    return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題１】チャンネル数の1に限定した一次元畳み込み層のクラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造は前のSprintで作成した全結合層のFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。\n",
    "\n",
    "\n",
    "ここでは パディング は考えず、ストライド も1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "\n",
    "$$a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b$$\n",
    "\n",
    "𝑎𝑖 : 出力される配列のi番目の値\n",
    "\n",
    "\n",
    "𝐹 : フィルタのサイズ\n",
    "\n",
    "\n",
    "𝑥(𝑖+𝑠) : 入力の配列の(i+s)番目の値\n",
    "\n",
    "\n",
    "𝑤𝑠 : 重みの配列のs番目の値\n",
    "\n",
    "\n",
    "𝑏 : バイアス項\n",
    "\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "\n",
    "次に更新式です。ここがAdaGradなどに置き換えられる点は全結合層と同様です。\n",
    "\n",
    "\n",
    "$$w_s^{\\prime} = w_s - \\alpha \\frac{\\partial L}{\\partial w_s} \\\\\n",
    "b^{\\prime} = b - \\alpha \\frac{\\partial L}{\\partial b}$$\n",
    "\n",
    "𝛼 : 学習率\n",
    "\n",
    "\n",
    "∂𝐿∂𝑤𝑠 : 𝑤𝑠 に関する損失 𝐿 の勾配\n",
    "\n",
    "\n",
    "∂𝐿∂𝑏 : 𝑏 に関する損失 𝐿 の勾配\n",
    "\n",
    "\n",
    "勾配 ∂𝐿∂𝑤𝑠 や ∂𝐿∂𝑏 を求めるためのバックプロパゲーションの数式が以下です。\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_s} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}x_{(i+s)}\\\\\n",
    "\\frac{\\partial L}{\\partial b} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}$$\n",
    "\n",
    "∂𝐿∂𝑎𝑖 : 勾配の配列のi番目の値\n",
    "\n",
    "\n",
    "𝑁𝑜𝑢𝑡 : 出力のサイズ\n",
    "\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial x_j} = \\sum_{s=0}^{F-1} \\frac{\\partial L}{\\partial a_{(j-s)}}w_s$$\n",
    "\n",
    "∂𝐿∂𝑥𝑗 : 前の層に流す誤差の配列のj番目の値\n",
    "\n",
    "\n",
    "ただし、 𝑗−𝑠<0 または 𝑗−𝑠>𝑁𝑜𝑢𝑡−1 のとき ∂𝐿∂𝑎(𝑗−𝑠)=0 です。\n",
    "\n",
    "\n",
    "全結合層との大きな違いは、重みが複数の特徴量に対して共有されていることです。この場合は共有されている分の誤差を全て足すことで勾配を求めます。計算グラフ上での分岐はバックプロパゲーションの際に誤差の足し算をすれば良いことになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1d_:\n",
    "    def __init__(self, initializer, optimizer, layer):\n",
    "        self.B = initializer.B()\n",
    "        self.W = initializer.W()\n",
    "        self.optimizer = optimizer\n",
    "        self.layer = layer\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.n_out = calc_out_shape(X.shape[0], W.shape[0]) #出力データ数\n",
    "        \n",
    "        self.in_data = np.array([X[n:n+W.shape[0]] for n in range(self.n_out)]) #Xを2次元の行列に加工する\n",
    "        \n",
    "        A = self.in_data @ self.W.T + self.B #forwardの計算\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dB = np.sum(dA)\n",
    "        dW = self.in_data.T @ dA\n",
    "        \n",
    "        \n",
    "        dX = []\n",
    "        for j in range(len(X)):\n",
    "            dX_j = []\n",
    "            for s in range(len(self.W)):\n",
    "                if j - s < 0 or j -s > self.n_out - 1:\n",
    "                    dX_j.append(0)\n",
    "                else:\n",
    "                    dX_j.append(dA[j - s] * self.W[s])\n",
    "                    \n",
    "            dX.append(sum(dX_j))\n",
    "        \n",
    "        dX = np.array(dX)\n",
    "        \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】小さな配列での1次元畳み込み層の実験"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォワードプロパゲーションでは入力とパラメータが以下のようになっているとき"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力はこうなっているはずです\n",
    "```python\n",
    "a = np.array([35, 50])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(X, W, B):\n",
    "    n_out = int(calc_out_shape(len(X), len(W), pad=0, stride=1))\n",
    "    n_out = int(calc_out_shape(X.shape[0], W.shape[0])) #出力データ数\n",
    "    in_data = np.array([X[n:n+W.shape[0]] for n in range(n_out)]) #Xを2次元の行列に加工する\n",
    "    A = in_data @ W.T + B #forwardの計算\n",
    "\n",
    "    return A\n",
    "\n",
    "forward(x, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バックプロパゲーションで誤差が以下のようなとき"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "delta_b = np.array([30])\n",
    "delta_w = np.array([50, 80, 110])\n",
    "delta_x = np.array([30, 110, 170, 140])\n",
    "```\n",
    "と、このようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, array([ 50,  80, 110]), array([ 30, 110, 170, 140]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backward(dA, X, W, B):\n",
    "    n_out = int(calc_out_shape(len(X), len(W), pad=0, stride=1))\n",
    "    \n",
    "    dB = np.sum(dA)\n",
    "    \n",
    "    in_data = np.array([X[n:n+W.shape[0]] for n in range(n_out)])\n",
    "    dW = in_data.T @ dA\n",
    "\n",
    "    dX = []\n",
    "    for j in range(len(X)):\n",
    "        dX_j = []\n",
    "        for s in range(len(W)):\n",
    "            if j - s < 0 or j -s > n_out - 1:\n",
    "                dX_j.append(0)\n",
    "            else:\n",
    "                dX_j.append(dA[j - s] * W[s])\n",
    "\n",
    "        dX.append(sum(dX_j))\n",
    "\n",
    "    dX = np.array(dX)\n",
    "\n",
    "    return dB, dW, dX\n",
    "\n",
    "backward(delta_a, x, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward、back共に問題無し。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題３と同じく出力を確認しましょう。\n",
    "\n",
    "フォワードプロパゲーションでは入力とパラメータが以下のようになっているとき"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "a = np.array([[16, 22], [17, 23], [18, 24]])\n",
    "```\n",
    "\n",
    "となっていれば正解です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 4],\n",
       "        [2, 3, 4, 5]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(1, 2, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN1dクラスよりforward抜粋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16., 22.],\n",
       "        [17., 23.],\n",
       "        [18., 24.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(X, W, B, stride):\n",
    "    \"\"\"\n",
    "    X : 次の形のndarray, shape (batch_size, n_in_ch, n_features)\n",
    "\n",
    "    W : 次の形のndarray, shape (n_out_ch, n_in_ch, fillter_size)\n",
    "\n",
    "    \"\"\"\n",
    "    n_out = int(calc_out_shape(X.shape[2], W.shape[2], pad=0, stride=1))\n",
    "\n",
    "    A = [] #batch_size毎のデータ\n",
    "    for k in range(X.shape[0]):\n",
    "        out_data = [] #n_out_ch毎のデータ\n",
    "        for j in range(W.shape[0]):\n",
    "            in_data_w = []\n",
    "            for i in range(X.shape[1]): #Xをチャンネル毎に加工する\n",
    "                in_data = np.array([X[k][i][n*stride : n*stride + W.shape[2]] for n in range(n_out)]) #２次元に加工\n",
    "                in_data_w.append(in_data @ W[j][i].T) #重みを掛けてリストへ格納\n",
    "\n",
    "            out_data_1ch = np.array(in_data_w).sum(axis=0) + B[j] #入力チャンネル分を合計してバイアスを足す\n",
    "            out_data.append(out_data_1ch)\n",
    "        A.append(out_data) #リストへ格納\n",
    "\n",
    "    A = np.array(A)\n",
    "\n",
    "    return A\n",
    "\n",
    "forward(X, w, b, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題無し。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1d:\n",
    "    def __init__(self, n_in_ch, n_fillter, fillter_size, n_out, initializer, optimizer, layer):\n",
    "        self.n_in_ch = n_in_ch\n",
    "        self.n_out = n_out\n",
    "        self.B = initializer.B(n_fillter)\n",
    "        self.W = initializer.W(n_in_ch, n_fillter, fillter_size)\n",
    "        self.HB = 0\n",
    "        self.HW = 0\n",
    "        self.optimizer = optimizer\n",
    "        self.layer = layer\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X : 次の形のndarray, shape (batch_size, n_in_ch, n_features)\n",
    "        \n",
    "        W : 次の形のndarray, shape (n_out_ch, n_in_ch, fillter_size)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        \n",
    "        #【問題5】（アドバンス課題）パディングの実装　（前後ゼロパディング処理）\n",
    "        X_pad = np.pad(X, [(0,0), (0,0), (self.layer.n_pad, self.layer.n_pad)], 'constant', constant_values=0)\n",
    "\n",
    "        #【問題7】（アドバンス課題）任意のストライド数\n",
    "        \n",
    "        self.in_data_back = []\n",
    "        \n",
    "        A = [] #batch_size毎のデータ\n",
    "        for k in range(X_pad.shape[0]):\n",
    "            out_data = [] #n_out_ch毎のデータ\n",
    "            for j in range(self.W.shape[0]):\n",
    "                in_data_w = []\n",
    "                for i in range(X_pad.shape[1]): #Xをチャンネル毎に加工する\n",
    "                    in_data = np.array([X_pad[k][i][n*self.layer.stride : n*self.layer.stride + self.W.shape[2]] for n in range(self.n_out)]) #２次元に加工\n",
    "                    in_data_w.append(in_data @ self.W[j][i].T) #重みを掛けてリストへ格納\n",
    "                    self.in_data_back.append(in_data)\n",
    "\n",
    "                out_data_1ch = np.array(in_data_w).sum(axis=0) + self.B[j] #入力チャンネル分を合計してバイアスを足す\n",
    "                out_data.append(out_data_1ch)\n",
    "            A.append(out_data) #リストへ格納\n",
    "\n",
    "        self.in_data = in_data\n",
    "        A = np.array(A)\n",
    "   \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dB = np.sum(np.sum(dA, axis=2), axis=0) / self.layer.batch_size\n",
    "        \n",
    "        #dWの処理\n",
    "        in_data = self.in_data_back[0:self.X.shape[1]]\n",
    "        dW = []\n",
    "        for k in range(self.X.shape[0]):\n",
    "            dW_out = []\n",
    "            for j in range(self.W.shape[0]):#出力チャンネル毎に処理\n",
    "                dW_1out = [] #出力１チャンネル分のdW\n",
    "                for i in range(self.X.shape[1]): #入力チャンネル毎に処理\n",
    "                    dW_1out.append(in_data[i].T @ dA[k][j]) #重みを掛けてリストへ格納    \n",
    "                dW_out.append(dW_1out)\n",
    "            dW.append(dW_out) #dWリストへ格納      \n",
    "        \n",
    "        dW = np.array(dW).sum(axis=0) / self.layer.batch_size\n",
    "        \n",
    "        #dXの処理\n",
    "        dX_batch = [] #batch_size毎のデータ\n",
    "        for x0 in range(self.X.shape[0]):\n",
    "            dX_out_ch = [] #n_out_ch毎のデータ\n",
    "            for out_ch in range(self.W.shape[0]):\n",
    "                dX_in_ch = [] #n_in_ch毎のデータ\n",
    "                for in_ch in range(self.X.shape[1]):\n",
    "                    dX_row = []\n",
    "                    for j in range(self.X.shape[2]):\n",
    "                        dX_j = []\n",
    "                        for s in range(self.W.shape[2]):\n",
    "                            if j - s < 0 or j -s > self.n_out - 1:\n",
    "                                dX_j.append(0)\n",
    "                            else:\n",
    "                                dX_j.append(dA[x0][in_ch][j - s] * self.W[out_ch][in_ch][s])\n",
    "                        dX_row.append(sum(dX_j))\n",
    "                    dX_in_ch.append(dX_row)\n",
    "                dX_out_ch.append(dX_in_ch)\n",
    "            one_sample = np.array(dX_out_ch).sum(axis=0)\n",
    "            dX_batch.append(one_sample)  \n",
    "            \n",
    "        dX = np.array(dX_batch)\n",
    "        \n",
    "        self.dB = dB\n",
    "        self.dW = dW\n",
    "        \n",
    "        # 更新\n",
    "        if self.layer.optimizer == \"SGD\":\n",
    "            self.B, self.W = self.optimizer.update(self)\n",
    "        elif self.layer.optimizer == \"AdaGrad\":\n",
    "            self.B, self.W, self.HB, self.HW = self.optimizer.update(self)\n",
    "\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】（アドバンス課題）パディングの実装\n",
    "畳み込み層にパディングの機能を加えてください。1次元配列の場合、前後にn個特徴量を増やせるようにしてください。\n",
    "\n",
    "\n",
    "最も単純なパディングは全て0で埋める ゼロパディング であり、CNNでは一般的です。他に端の値を繰り返す方法などもあります。\n",
    "\n",
    "\n",
    "フレームワークによっては、元の入力のサイズを保つようにという指定をすることができます。この機能も持たせておくと便利です。なお、NumPyにはパディングの関数が存在します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】（アドバンス課題）ミニバッチへの対応\n",
    "ここまでの課題はバッチサイズ1で良いとしてきました。しかし、実際は全結合層同様にミニバッチ学習が行われます。Conv1dクラスを複数のデータが同時に計算できるように変更してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】（アドバンス課題）任意のストライド数\n",
    "ストライドは1限定の実装をしてきましたが、任意のストライド数に対応できるようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題５〜７の回答はCNN1dクラス及びScratch1dCNNClassifierクラス内に記載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】学習と推定\n",
    "\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "\n",
    "出力層だけは全結合層をそのまま使ってください。ただし、チャンネルが複数ある状態では全結合層への入力は行えません。その段階でのチャンネルは1になるようにするか、 平滑化 を行なってください。\n",
    "\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        pass    \n",
    "       \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X : 次の形のndarray, shape (batch_size, n_in_ch, n_features)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        \n",
    "        flatten_f = X.reshape(X.shape[0], -1)\n",
    "        \n",
    "        return flatten_f\n",
    "    \n",
    "    def backward(self,dA):\n",
    "        \"\"\"\n",
    "        dA : 次の形のndarray, shape (batch_size, n_features)\n",
    "        \n",
    "        \"\"\"\n",
    "        flatten_b = dA.reshape(self.X.shape[0], -1, self.X.shape[2])\n",
    "        \n",
    "        return flatten_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Connected Layer Class\n",
    "class FC:\n",
    "    \"\"\"\n",
    "   全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, layer):\n",
    "        self.optimizer = optimizer\n",
    "        self.layer = layer \n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2, None)\n",
    "        \n",
    "        self.HB = 0\n",
    "        self.HW = 0\n",
    "        \n",
    "    def forward(self, X): #X or Z\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        self.X = X #X or Z\n",
    "\n",
    "        A = X @ self.W + self.B\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dB = np.sum(dA, axis=0) / self.layer.batch_size\n",
    "        dW = self.X.T @ dA / self.layer.batch_size\n",
    "        dZ = dA @ self.W.T\n",
    "        \n",
    "        self.dB = dB\n",
    "        self.dW = dW\n",
    "        \n",
    "\n",
    "        # 更新\n",
    "        if self.layer.optimizer == \"SGD\":\n",
    "            self.B, self.W = self.optimizer.update(self)\n",
    "        elif self.layer.optimizer == \"AdaGrad\":\n",
    "            self.B, self.W, self.HB, self.HW = self.optimizer.update(self)\n",
    "            \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xavierの初期値\n",
    "class XavierInitializer:\n",
    "    def W(self, n_in, n_out, fillter_size):\n",
    "        sigma = 1/np.sqrt(n_in)\n",
    "        if fillter_size == None:\n",
    "            W = sigma * np.random.randn(n_in, n_out) #重みの初期値(全結合層)\n",
    "        else:\n",
    "            W = sigma * np.random.randn(n_out, n_in, fillter_size) #重みの初期値（畳み込み層）\n",
    "        return W\n",
    "\n",
    "    def B(self, n_out):\n",
    "        sigma = 1/np.sqrt(n_out)\n",
    "        B = sigma * np.random.randn(n_out) #バイアスの初期値\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heの初期値\n",
    "class HeInitializer:\n",
    "    def W(self, n_in, n_out, fillter_size):\n",
    "        sigma = np.sqrt(2/n_in)\n",
    "        if fillter_size == None:\n",
    "            W = sigma * np.random.randn(n_in, n_out) #重みの初期値(全結合層)\n",
    "        else:\n",
    "            W = sigma * np.random.randn(n_out, n_in, fillter_size) #重みの初期値（畳み込み層）\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_out):\n",
    "        sigma = np.sqrt(2/n_out)\n",
    "        B = sigma * np.random.randn(n_out) #バイアスの初期値\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        B = layer.B - (self.lr * layer.dB) \n",
    "        W = layer.W - (self.lr * layer.dW)\n",
    "        \n",
    "        return B, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        HB = layer.HB + layer.dB**2\n",
    "        B = layer.B - (self.lr * (1/(np.sqrt(HB) + 1e-7)) * layer.dB)\n",
    "\n",
    "        HW = layer.HW + layer.dW**2\n",
    "        W = layer.W - (self.lr * (1/(np.sqrt(HW) + 1e-7)) * layer.dW)\n",
    "        \n",
    "        return B, W, HB, HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        Z = 1 / (1 + np.exp(-A)) #シグモイド関数\n",
    "        self.A = A\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * ((1 - (1 / (1 + np.exp(-self.A)))) * (1 / (1 + np.exp(-self.A)))) #Aに関する損失の勾配\n",
    "        return dA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        Z = np.tanh(A) #ハイパボリックタンジェント関数\n",
    "        self.A = A\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * (1 - np.tanh(self.A)**2) #Aに関する損失の勾配\n",
    "        return dA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        Z = np.maximum(0 + 1e-7, A)\n",
    "        self.mask = (Z <= 0 + 1e-7)\n",
    "        return Z \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dZ[self.mask] = 0 + 1e-7\n",
    "        dA = dZ \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        A = A - np.max(A, axis=1, keepdims=True) #オーバーフロー対策\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1, keepdims=True) #ソフトマックス関数\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, Z, Y):\n",
    "        dA = Z - Y  #Aに関する損失の勾配\n",
    "        loss = -1 * np.sum(Y * np.log(Z + 1e-7)) / Z.shape[0] #交差エントロピー誤差\n",
    "\n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch1dCNNClassifier:\n",
    "    def __init__(self, lr=10**-2, batch_size=20, activation_func=\"Tanh\", optimizer=\"AdaGrad\", \n",
    "                            n_pad=1, stride=2, fillter_size=3, n_fillter1=5, n_fillter2=10, n_epoch=1, verbose = False):\n",
    "        \n",
    "        self.lr = lr #学習率\n",
    "        self.batch_size = batch_size #バッチサイズ\n",
    "        self.activation_func = activation_func #活性化関数の種類\n",
    "        self.optimizer = optimizer #最適化手法\n",
    "        self.n_pad = n_pad #パディング数\n",
    "        self.stride = stride #ストライド数\n",
    "        self.fillter_size = fillter_size #フィルターサイズ\n",
    "        self.n_fillter1 = n_fillter1 #1層目フィルター数\n",
    "        self.n_fillter2 = n_fillter2 #2層目フィルター数\n",
    "        self.n_epoch =n_epoch #エポック数\n",
    "        self.loss_list = [] #損失を記録するリスト\n",
    "        self.loss_list_val = [] #損失を記録するリスト(検証データ用)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def calc_out_shape(self, n_in, fillter_size, n_pad, stride):\n",
    "        n_out = int((n_in + 2*n_pad - fillter_size) / stride + 1)\n",
    "        return n_out\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, cnt = 1):\n",
    "        X = X.reshape(X.shape[0], -1, X.shape[1]) #2次元→3次元データへreshape(サンプル数 :48000、チャンネル数 :1、特徴量数 :784)\n",
    "        self.n_features = X.shape[2]\n",
    "        self.n_in_ch = X.shape[1]\n",
    "        self.n_out1 = self.calc_out_shape(self.n_features, self.fillter_size, self.n_pad, self.stride)\n",
    "        self.n_out2 = self.calc_out_shape(self.n_out1, self.fillter_size, self.n_pad, self.stride)\n",
    "        self.n_output = y.shape[1]\n",
    "        if self.optimizer == \"SGD\":\n",
    "            optimizer = SGD(self.lr)\n",
    "        elif self.optimizer == \"AdaGrad\":\n",
    "            optimizer = AdaGrad(self.lr)\n",
    "        if self.activation_func == \"Tanh\":\n",
    "            activation = Tanh()\n",
    "            initializer = XavierInitializer() #Xavierの初期値\n",
    "        elif self.activation_func == \"Sigmoid\":\n",
    "            activation = Sigmoid()\n",
    "            initializer = XavierInitializer() #Xavierの初期値\n",
    "        elif self.activation_func == \"ReLU\":\n",
    "            activation = ReLU()\n",
    "            initializer = HeInitializer() #Heの初期値\n",
    "        self.CNN1d1 = CNN1d(self.n_in_ch, self.n_fillter1, self.fillter_size, self.n_out1, initializer, optimizer, self)\n",
    "        self.activation1 = deepcopy(activation)\n",
    "        self.CNN1d2 = CNN1d(self.n_fillter1, self.n_fillter2, self.fillter_size, self.n_out2, initializer, optimizer, self)\n",
    "        self.activation2 = deepcopy(activation)\n",
    "        self.Flatten = Flatten()\n",
    "        self.FC3 = FC(self.n_out2*self.n_fillter2, self.n_output, initializer, optimizer, self)\n",
    "        self.activation3 = Softmax()\n",
    "         \n",
    "        #fitを再帰させて学習データと検証データの両方を学習させる。検証データがあれば先に検証データを学習させる\n",
    "        if X_val is None:\n",
    "            get_mini_batch = GetMiniBatch(X, y, self.batch_size) #GetMiniBatchクラスでミニバッチを作成\n",
    "        else:\n",
    "            get_mini_batch = GetMiniBatch(X_val, y_val, self.batch_size) #GetMiniBatchクラスでミニバッチを作成\n",
    "        \n",
    "        #学習処理\n",
    "        for i in range(self.n_epoch):\n",
    "            loss_list = []\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # このfor文内でミニバッチが使える\n",
    "\n",
    "                #forwardの処理\n",
    "                A1 = self.CNN1d1.forward(mini_X_train)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                A2 = self.CNN1d2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                Z2_f = self.Flatten.forward(Z2)\n",
    "                A3 = self.FC3.forward(Z2_f)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "\n",
    "                #backwardの処理\n",
    "                dA3, loss = self.activation3.backward(Z3, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dZ2_f = self.Flatten.backward(dZ2)\n",
    "                dA2 = self.activation2.backward(dZ2_f)\n",
    "                dZ1 = self.CNN1d2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.CNN1d1.backward(dA1) # dZ0は使用しない\n",
    "                \n",
    "                \"\"\"\n",
    "                Loss Curvを描くための処理\n",
    "                \"\"\"                \n",
    "                loss_list.append(loss)\n",
    "\n",
    "            \n",
    "            if X_val is None:\n",
    "                self.loss_list.append(np.mean(loss_list))\n",
    "                if self.verbose: #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_list)\n",
    "            else:\n",
    "                self.loss_list_val.append(np.mean(loss_list))\n",
    "                if self.verbose: #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_list_val)\n",
    "                \n",
    "        cnt += 1\n",
    "        if cnt == 3 or X_val is None:\n",
    "            return\n",
    "        \n",
    "        return self.fit(X, y, cnt = cnt) #検証データが入力されている場合は再帰させて学習データを学習させる。\n",
    "\n",
    "    def predict(self,X):\n",
    "        X = X.reshape(X.shape[0], -1, X.shape[1]) #2次元→3次元データへreshape(サンプル数 :48000、チャンネル数 :1、特徴量数 :784)\n",
    "        A1 = self.CNN1d1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.CNN1d2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        Z2_f = self.Flatten.forward(Z2)\n",
    "        A3 = self.FC3.forward(Z2_f)\n",
    "        y = self.activation3.forward(A3)\n",
    "        \n",
    "        pred = np.argmax(y, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 10)\n",
      "(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.fit_transform(y_val[:, np.newaxis])\n",
    "print(y_train_one_hot.shape)\n",
    "print(y_val_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1dc = Scratch1dCNNClassifier(lr=10**-1, batch_size=20, activation_func=\"ReLU\", optimizer=\"AdaGrad\", \n",
    "                            n_pad=1, stride=3, fillter_size=6, n_fillter1=2, n_fillter2=2, n_epoch=10, verbose = False)\n",
    "s1dc.fit(X_train, y_train_one_hot)#, X_val, y_val_one_hot、計算に時間が掛かる為valは無し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 6 6]\n",
      "正解率：0.83\n",
      "混同行列：\n",
      "[[ 899    1    9    6    5   18   26    2    6    8]\n",
      " [   1 1106    5    6    5    3    5    1    3    0]\n",
      " [  30   19  822   35   17    8   55   14   24    8]\n",
      " [   2    1   41  824   15   64   17   18   12   16]\n",
      " [  21    2   18   13  747   12   37   23   27   82]\n",
      " [  15    9   31   94   19  610   61    6   34   13]\n",
      " [  18    2   16    1   13   10  887    0   10    1]\n",
      " [   1   17   17    7   31   11    2  896    4   42]\n",
      " [  11    5   33  117   47   40   25   15  658   23]\n",
      " [  18    3    5   26   40    5    1   42   15  854]]\n",
      "classification_report：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       980\n",
      "           1       0.95      0.97      0.96      1135\n",
      "           2       0.82      0.80      0.81      1032\n",
      "           3       0.73      0.82      0.77      1010\n",
      "           4       0.80      0.76      0.78       982\n",
      "           5       0.78      0.68      0.73       892\n",
      "           6       0.79      0.93      0.86       958\n",
      "           7       0.88      0.87      0.88      1028\n",
      "           8       0.83      0.68      0.74       974\n",
      "           9       0.82      0.85      0.83      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#テストデータ\n",
    "pred = s1dc.predict(X_test)\n",
    "print(pred)\n",
    "print(\"正解率：{:.2f}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"混同行列：\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"classification_report：\") #評価をまとめて出力するやつ\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"model loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(1, len(s1dc.loss_list)+1), s1dc.loss_list, label=\"train_loss\", marker=\"o\", linewidth=3)\n",
    "plt.plot(np.arange(1, len(s1dc.loss_list_val)+1), s1dc.loss_list_val, label=\"val_loss\", marker=\"o\", linewidth=3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### １パターンのみだが、正解率は0.83となった。実装にfor文を多用してしまい計算速度がめちゃくちゃ遅くなってしまった為、複数回実施することが出来なかった。今後は、魚本の中にある「image to column」の考え方を実装に取り入れ、計算速度の向上を図って行きたい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
