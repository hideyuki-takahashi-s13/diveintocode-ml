{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€å•é¡Œ2ã€‘1æ¬¡å…ƒç•³ã¿è¾¼ã¿å¾Œã®å‡ºåŠ›ã‚µã‚¤ã‚ºã®è¨ˆç®—\n",
    "\n",
    "$$\n",
    "N_{out} = \\frac{N_{in}+2P-F}{S}+1\n",
    "$$\n",
    "\n",
    "$N_{out}$ : å‡ºåŠ›ã®ã‚µã‚¤ã‚ºï¼ˆç‰¹å¾´é‡ã®æ•°ï¼‰\n",
    "\n",
    "\n",
    "$N_{in}$ : å…¥åŠ›ã®ã‚µã‚¤ã‚ºï¼ˆç‰¹å¾´é‡ã®æ•°ï¼‰\n",
    "\n",
    "\n",
    "$P$ : ã‚ã‚‹æ–¹å‘ã¸ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®æ•°\n",
    "\n",
    "\n",
    "$F$ : ãƒ•ã‚£ãƒ«ã‚¿ã®ã‚µã‚¤ã‚º\n",
    "\n",
    "\n",
    "$S$ : ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã®ã‚µã‚¤ã‚º\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_out_shape(n_in, fill_size, pad=0, stride=1):\n",
    "    n_out = (n_in + 2*pad - fill_size) / stride + 1\n",
    "    return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€å•é¡Œï¼‘ã€‘ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã®1ã«é™å®šã—ãŸä¸€æ¬¡å…ƒç•³ã¿è¾¼ã¿å±¤ã®ã‚¯ãƒ©ã‚¹ã®ä½œæˆ\n",
    "ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’1ã«é™å®šã—ãŸ1æ¬¡å…ƒç•³ã¿è¾¼ã¿å±¤ã®ã‚¯ãƒ©ã‚¹SimpleConv1dã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚åŸºæœ¬æ§‹é€ ã¯å‰ã®Sprintã§ä½œæˆã—ãŸå…¨çµåˆå±¤ã®FCã‚¯ãƒ©ã‚¹ã¨åŒã˜ã«ãªã‚Šã¾ã™ã€‚ãªãŠã€é‡ã¿ã®åˆæœŸåŒ–ã«é–¢ã™ã‚‹ã‚¯ãƒ©ã‚¹ã¯å¿…è¦ã«å¿œã˜ã¦ä½œã‚Šå¤‰ãˆã¦ãã ã•ã„ã€‚Xavierã®åˆæœŸå€¤ãªã©ã‚’ä½¿ã†ç‚¹ã¯å…¨çµåˆå±¤ã¨åŒæ§˜ã§ã™ã€‚\n",
    "\n",
    "\n",
    "ã“ã“ã§ã¯ ãƒ‘ãƒ‡ã‚£ãƒ³ã‚° ã¯è€ƒãˆãšã€ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ ã‚‚1ã«å›ºå®šã—ã¾ã™ã€‚ã¾ãŸã€è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŒæ™‚ã«å‡¦ç†ã™ã‚‹ã“ã¨ã‚‚è€ƒãˆãªãã¦è‰¯ãã€ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯1ã®ã¿ã«å¯¾å¿œã—ã¦ãã ã•ã„ã€‚ã“ã®éƒ¨åˆ†ã®æ‹¡å¼µã¯ã‚¢ãƒ‰ãƒãƒ³ã‚¹èª²é¡Œã¨ã—ã¾ã™ã€‚\n",
    "\n",
    "\n",
    "ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã®æ•°å¼ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "\n",
    "$$a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b$$\n",
    "\n",
    "ğ‘ğ‘– : å‡ºåŠ›ã•ã‚Œã‚‹é…åˆ—ã®iç•ªç›®ã®å€¤\n",
    "\n",
    "\n",
    "ğ¹ : ãƒ•ã‚£ãƒ«ã‚¿ã®ã‚µã‚¤ã‚º\n",
    "\n",
    "\n",
    "ğ‘¥(ğ‘–+ğ‘ ) : å…¥åŠ›ã®é…åˆ—ã®(i+s)ç•ªç›®ã®å€¤\n",
    "\n",
    "\n",
    "ğ‘¤ğ‘  : é‡ã¿ã®é…åˆ—ã®sç•ªç›®ã®å€¤\n",
    "\n",
    "\n",
    "ğ‘ : ãƒã‚¤ã‚¢ã‚¹é …\n",
    "\n",
    "\n",
    "å…¨ã¦ã‚¹ã‚«ãƒ©ãƒ¼ã§ã™ã€‚\n",
    "\n",
    "\n",
    "æ¬¡ã«æ›´æ–°å¼ã§ã™ã€‚ã“ã“ãŒAdaGradãªã©ã«ç½®ãæ›ãˆã‚‰ã‚Œã‚‹ç‚¹ã¯å…¨çµåˆå±¤ã¨åŒæ§˜ã§ã™ã€‚\n",
    "\n",
    "\n",
    "$$w_s^{\\prime} = w_s - \\alpha \\frac{\\partial L}{\\partial w_s} \\\\\n",
    "b^{\\prime} = b - \\alpha \\frac{\\partial L}{\\partial b}$$\n",
    "\n",
    "ğ›¼ : å­¦ç¿’ç‡\n",
    "\n",
    "\n",
    "âˆ‚ğ¿âˆ‚ğ‘¤ğ‘  : ğ‘¤ğ‘  ã«é–¢ã™ã‚‹æå¤± ğ¿ ã®å‹¾é…\n",
    "\n",
    "\n",
    "âˆ‚ğ¿âˆ‚ğ‘ : ğ‘ ã«é–¢ã™ã‚‹æå¤± ğ¿ ã®å‹¾é…\n",
    "\n",
    "\n",
    "å‹¾é… âˆ‚ğ¿âˆ‚ğ‘¤ğ‘  ã‚„ âˆ‚ğ¿âˆ‚ğ‘ ã‚’æ±‚ã‚ã‚‹ãŸã‚ã®ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã®æ•°å¼ãŒä»¥ä¸‹ã§ã™ã€‚\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_s} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}x_{(i+s)}\\\\\n",
    "\\frac{\\partial L}{\\partial b} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}$$\n",
    "\n",
    "âˆ‚ğ¿âˆ‚ğ‘ğ‘– : å‹¾é…ã®é…åˆ—ã®iç•ªç›®ã®å€¤\n",
    "\n",
    "\n",
    "ğ‘ğ‘œğ‘¢ğ‘¡ : å‡ºåŠ›ã®ã‚µã‚¤ã‚º\n",
    "\n",
    "\n",
    "å‰ã®å±¤ã«æµã™èª¤å·®ã®æ•°å¼ã¯ä»¥ä¸‹ã§ã™ã€‚\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial x_j} = \\sum_{s=0}^{F-1} \\frac{\\partial L}{\\partial a_{(j-s)}}w_s$$\n",
    "\n",
    "âˆ‚ğ¿âˆ‚ğ‘¥ğ‘— : å‰ã®å±¤ã«æµã™èª¤å·®ã®é…åˆ—ã®jç•ªç›®ã®å€¤\n",
    "\n",
    "\n",
    "ãŸã ã—ã€ ğ‘—âˆ’ğ‘ <0 ã¾ãŸã¯ ğ‘—âˆ’ğ‘ >ğ‘ğ‘œğ‘¢ğ‘¡âˆ’1 ã®ã¨ã âˆ‚ğ¿âˆ‚ğ‘(ğ‘—âˆ’ğ‘ )=0 ã§ã™ã€‚\n",
    "\n",
    "\n",
    "å…¨çµåˆå±¤ã¨ã®å¤§ããªé•ã„ã¯ã€é‡ã¿ãŒè¤‡æ•°ã®ç‰¹å¾´é‡ã«å¯¾ã—ã¦å…±æœ‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã§ã™ã€‚ã“ã®å ´åˆã¯å…±æœ‰ã•ã‚Œã¦ã„ã‚‹åˆ†ã®èª¤å·®ã‚’å…¨ã¦è¶³ã™ã“ã¨ã§å‹¾é…ã‚’æ±‚ã‚ã¾ã™ã€‚è¨ˆç®—ã‚°ãƒ©ãƒ•ä¸Šã§ã®åˆ†å²ã¯ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã®éš›ã«èª¤å·®ã®è¶³ã—ç®—ã‚’ã™ã‚Œã°è‰¯ã„ã“ã¨ã«ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1d_:\n",
    "    def __init__(self, initializer, optimizer, layer):\n",
    "        self.B = initializer.B()\n",
    "        self.W = initializer.W()\n",
    "        self.optimizer = optimizer\n",
    "        self.layer = layer\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.n_out = calc_out_shape(X.shape[0], W.shape[0]) #å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿æ•°\n",
    "        \n",
    "        self.in_data = np.array([X[n:n+W.shape[0]] for n in range(self.n_out)]) #Xã‚’2æ¬¡å…ƒã®è¡Œåˆ—ã«åŠ å·¥ã™ã‚‹\n",
    "        \n",
    "        A = self.in_data @ self.W.T + self.B #forwardã®è¨ˆç®—\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dB = np.sum(dA)\n",
    "        dW = self.in_data.T @ dA\n",
    "        \n",
    "        \n",
    "        dX = []\n",
    "        for j in range(len(X)):\n",
    "            dX_j = []\n",
    "            for s in range(len(self.W)):\n",
    "                if j - s < 0 or j -s > self.n_out - 1:\n",
    "                    dX_j.append(0)\n",
    "                else:\n",
    "                    dX_j.append(dA[j - s] * self.W[s])\n",
    "                    \n",
    "            dX.append(sum(dX_j))\n",
    "        \n",
    "        dX = np.array(dX)\n",
    "        \n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€å•é¡Œ3ã€‘å°ã•ãªé…åˆ—ã§ã®1æ¬¡å…ƒç•³ã¿è¾¼ã¿å±¤ã®å®Ÿé¨“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯å…¥åŠ›ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä»¥ä¸‹ã®ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã¨ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‡ºåŠ›ã¯ã“ã†ãªã£ã¦ã„ã‚‹ã¯ãšã§ã™\n",
    "```python\n",
    "a = np.array([35, 50])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(X, W, B):\n",
    "    n_out = int(calc_out_shape(len(X), len(W), pad=0, stride=1))\n",
    "    n_out = int(calc_out_shape(X.shape[0], W.shape[0])) #å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿æ•°\n",
    "    in_data = np.array([X[n:n+W.shape[0]] for n in range(n_out)]) #Xã‚’2æ¬¡å…ƒã®è¡Œåˆ—ã«åŠ å·¥ã™ã‚‹\n",
    "    A = in_data @ W.T + B #forwardã®è¨ˆç®—\n",
    "\n",
    "    return A\n",
    "\n",
    "forward(x, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã§èª¤å·®ãŒä»¥ä¸‹ã®ã‚ˆã†ãªã¨ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_a = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "delta_b = np.array([30])\n",
    "delta_w = np.array([50, 80, 110])\n",
    "delta_x = np.array([30, 110, 170, 140])\n",
    "```\n",
    "ã¨ã€ã“ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, array([ 50,  80, 110]), array([ 30, 110, 170, 140]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backward(dA, X, W, B):\n",
    "    n_out = int(calc_out_shape(len(X), len(W), pad=0, stride=1))\n",
    "    \n",
    "    dB = np.sum(dA)\n",
    "    \n",
    "    in_data = np.array([X[n:n+W.shape[0]] for n in range(n_out)])\n",
    "    dW = in_data.T @ dA\n",
    "\n",
    "    dX = []\n",
    "    for j in range(len(X)):\n",
    "        dX_j = []\n",
    "        for s in range(len(W)):\n",
    "            if j - s < 0 or j -s > n_out - 1:\n",
    "                dX_j.append(0)\n",
    "            else:\n",
    "                dX_j.append(dA[j - s] * W[s])\n",
    "\n",
    "        dX.append(sum(dX_j))\n",
    "\n",
    "    dX = np.array(dX)\n",
    "\n",
    "    return dB, dW, dX\n",
    "\n",
    "backward(delta_a, x, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forwardã€backå…±ã«å•é¡Œç„¡ã—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€å•é¡Œ4ã€‘ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã‚’é™å®šã—ãªã„1æ¬¡å…ƒç•³ã¿è¾¼ã¿å±¤ã‚¯ãƒ©ã‚¹ã®ä½œæˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å•é¡Œï¼“ã¨åŒã˜ãå‡ºåŠ›ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚\n",
    "\n",
    "ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯å…¥åŠ›ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒä»¥ä¸‹ã®ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã¨ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)ã§ã€ï¼ˆå…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã€ç‰¹å¾´é‡æ•°ï¼‰ã§ã‚ã‚‹ã€‚\n",
    "w = np.ones((3, 2, 3)) # ä¾‹ã®ç°¡ç•¥åŒ–ã®ãŸã‚å…¨ã¦1ã¨ã™ã‚‹ã€‚(å‡ºåŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã€å…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã€ãƒ•ã‚£ãƒ«ã‚¿ã‚µã‚¤ã‚º)ã§ã‚ã‚‹ã€‚\n",
    "b = np.array([1, 2, 3]) # ï¼ˆå‡ºåŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ•°ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "a = np.array([[16, 22], [17, 23], [18, 24]])\n",
    "```\n",
    "\n",
    "ã¨ãªã£ã¦ã„ã‚Œã°æ­£è§£ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3, 4],\n",
       "        [2, 3, 4, 5]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(1, 2, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN1dã‚¯ãƒ©ã‚¹ã‚ˆã‚ŠforwardæŠœç²‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[16., 22.],\n",
       "        [17., 23.],\n",
       "        [18., 24.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def forward(X, W, B, stride):\n",
    "    \"\"\"\n",
    "    X : æ¬¡ã®å½¢ã®ndarray, shape (batch_size, n_in_ch, n_features)\n",
    "\n",
    "    W : æ¬¡ã®å½¢ã®ndarray, shape (n_out_ch, n_in_ch, fillter_size)\n",
    "\n",
    "    \"\"\"\n",
    "    n_out = int(calc_out_shape(X.shape[2], W.shape[2], pad=0, stride=1))\n",
    "\n",
    "    A = [] #batch_sizeæ¯ã®ãƒ‡ãƒ¼ã‚¿\n",
    "    for k in range(X.shape[0]):\n",
    "        out_data = [] #n_out_chæ¯ã®ãƒ‡ãƒ¼ã‚¿\n",
    "        for j in range(W.shape[0]):\n",
    "            in_data_w = []\n",
    "            for i in range(X.shape[1]): #Xã‚’ãƒãƒ£ãƒ³ãƒãƒ«æ¯ã«åŠ å·¥ã™ã‚‹\n",
    "                in_data = np.array([X[k][i][n*stride : n*stride + W.shape[2]] for n in range(n_out)]) #ï¼’æ¬¡å…ƒã«åŠ å·¥\n",
    "                in_data_w.append(in_data @ W[j][i].T) #é‡ã¿ã‚’æ›ã‘ã¦ãƒªã‚¹ãƒˆã¸æ ¼ç´\n",
    "\n",
    "            out_data_1ch = np.array(in_data_w).sum(axis=0) + B[j] #å…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«åˆ†ã‚’åˆè¨ˆã—ã¦ãƒã‚¤ã‚¢ã‚¹ã‚’è¶³ã™\n",
    "            out_data.append(out_data_1ch)\n",
    "        A.append(out_data) #ãƒªã‚¹ãƒˆã¸æ ¼ç´\n",
    "\n",
    "    A = np.array(A)\n",
    "\n",
    "    return A\n",
    "\n",
    "forward(X, w, b, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å•é¡Œç„¡ã—ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1d:\n",
    "    def __init__(self, n_in_ch, n_fillter, fillter_size, n_out, initializer, optimizer, layer):\n",
    "        self.n_in_ch = n_in_ch\n",
    "        self.n_out = n_out\n",
    "        self.B = initializer.B(n_fillter)\n",
    "        self.W = initializer.W(n_in_ch, n_fillter, fillter_size)\n",
    "        self.HB = 0\n",
    "        self.HW = 0\n",
    "        self.optimizer = optimizer\n",
    "        self.layer = layer\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X : æ¬¡ã®å½¢ã®ndarray, shape (batch_size, n_in_ch, n_features)\n",
    "        \n",
    "        W : æ¬¡ã®å½¢ã®ndarray, shape (n_out_ch, n_in_ch, fillter_size)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        \n",
    "        #ã€å•é¡Œ5ã€‘ï¼ˆã‚¢ãƒ‰ãƒãƒ³ã‚¹èª²é¡Œï¼‰ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®å®Ÿè£…ã€€ï¼ˆå‰å¾Œã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å‡¦ç†ï¼‰\n",
    "        X_pad = np.pad(X, [(0,0), (0,0), (self.layer.n_pad, self.layer.n_pad)], 'constant', constant_values=0)\n",
    "\n",
    "        #ã€å•é¡Œ7ã€‘ï¼ˆã‚¢ãƒ‰ãƒãƒ³ã‚¹èª²é¡Œï¼‰ä»»æ„ã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰æ•°\n",
    "        \n",
    "        self.in_data_back = []\n",
    "        \n",
    "        A = [] #batch_sizeæ¯ã®ãƒ‡ãƒ¼ã‚¿\n",
    "        for k in range(X_pad.shape[0]):\n",
    "            out_data = [] #n_out_chæ¯ã®ãƒ‡ãƒ¼ã‚¿\n",
    "            for j in range(self.W.shape[0]):\n",
    "                in_data_w = []\n",
    "                for i in range(X_pad.shape[1]): #Xã‚’ãƒãƒ£ãƒ³ãƒãƒ«æ¯ã«åŠ å·¥ã™ã‚‹\n",
    "                    in_data = np.array([X_pad[k][i][n*self.layer.stride : n*self.layer.stride + self.W.shape[2]] for n in range(self.n_out)]) #ï¼’æ¬¡å…ƒã«åŠ å·¥\n",
    "                    in_data_w.append(in_data @ self.W[j][i].T) #é‡ã¿ã‚’æ›ã‘ã¦ãƒªã‚¹ãƒˆã¸æ ¼ç´\n",
    "                    self.in_data_back.append(in_data)\n",
    "\n",
    "                out_data_1ch = np.array(in_data_w).sum(axis=0) + self.B[j] #å…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«åˆ†ã‚’åˆè¨ˆã—ã¦ãƒã‚¤ã‚¢ã‚¹ã‚’è¶³ã™\n",
    "                out_data.append(out_data_1ch)\n",
    "            A.append(out_data) #ãƒªã‚¹ãƒˆã¸æ ¼ç´\n",
    "\n",
    "        self.in_data = in_data\n",
    "        A = np.array(A)\n",
    "   \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        dB = np.sum(np.sum(dA, axis=2), axis=0) / self.layer.batch_size\n",
    "        \n",
    "        #dWã®å‡¦ç†\n",
    "        in_data = self.in_data_back[0:self.X.shape[1]]\n",
    "        dW = []\n",
    "        for k in range(self.X.shape[0]):\n",
    "            dW_out = []\n",
    "            for j in range(self.W.shape[0]):#å‡ºåŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ¯ã«å‡¦ç†\n",
    "                dW_1out = [] #å‡ºåŠ›ï¼‘ãƒãƒ£ãƒ³ãƒãƒ«åˆ†ã®dW\n",
    "                for i in range(self.X.shape[1]): #å…¥åŠ›ãƒãƒ£ãƒ³ãƒãƒ«æ¯ã«å‡¦ç†\n",
    "                    dW_1out.append(in_data[i].T @ dA[k][j]) #é‡ã¿ã‚’æ›ã‘ã¦ãƒªã‚¹ãƒˆã¸æ ¼ç´    \n",
    "                dW_out.append(dW_1out)\n",
    "            dW.append(dW_out) #dWãƒªã‚¹ãƒˆã¸æ ¼ç´      \n",
    "        \n",
    "        dW = np.array(dW).sum(axis=0) / self.layer.batch_size\n",
    "        \n",
    "        #dXã®å‡¦ç†\n",
    "        dX_batch = [] #batch_sizeæ¯ã®ãƒ‡ãƒ¼ã‚¿\n",
    "        for x0 in range(self.X.shape[0]):\n",
    "            dX_out_ch = [] #n_out_chæ¯ã®ãƒ‡ãƒ¼ã‚¿\n",
    "            for out_ch in range(self.W.shape[0]):\n",
    "                dX_in_ch = [] #n_in_chæ¯ã®ãƒ‡ãƒ¼ã‚¿\n",
    "                for in_ch in range(self.X.shape[1]):\n",
    "                    dX_row = []\n",
    "                    for j in range(self.X.shape[2]):\n",
    "                        dX_j = []\n",
    "                        for s in range(self.W.shape[2]):\n",
    "                            if j - s < 0 or j -s > self.n_out - 1:\n",
    "                                dX_j.append(0)\n",
    "                            else:\n",
    "                                dX_j.append(dA[x0][in_ch][j - s] * self.W[out_ch][in_ch][s])\n",
    "                        dX_row.append(sum(dX_j))\n",
    "                    dX_in_ch.append(dX_row)\n",
    "                dX_out_ch.append(dX_in_ch)\n",
    "            one_sample = np.array(dX_out_ch).sum(axis=0)\n",
    "            dX_batch.append(one_sample)  \n",
    "            \n",
    "        dX = np.array(dX_batch)\n",
    "        \n",
    "        self.dB = dB\n",
    "        self.dW = dW\n",
    "        \n",
    "        # æ›´æ–°\n",
    "        if self.layer.optimizer == \"SGD\":\n",
    "            self.B, self.W = self.optimizer.update(self)\n",
    "        elif self.layer.optimizer == \"AdaGrad\":\n",
    "            self.B, self.W, self.HB, self.HW = self.optimizer.update(self)\n",
    "\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€å•é¡Œ5ã€‘ï¼ˆã‚¢ãƒ‰ãƒãƒ³ã‚¹èª²é¡Œï¼‰ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®å®Ÿè£…\n",
    "ç•³ã¿è¾¼ã¿å±¤ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®æ©Ÿèƒ½ã‚’åŠ ãˆã¦ãã ã•ã„ã€‚1æ¬¡å…ƒé…åˆ—ã®å ´åˆã€å‰å¾Œã«nå€‹ç‰¹å¾´é‡ã‚’å¢—ã‚„ã›ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "\n",
    "æœ€ã‚‚å˜ç´”ãªãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã¯å…¨ã¦0ã§åŸ‹ã‚ã‚‹ ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚° ã§ã‚ã‚Šã€CNNã§ã¯ä¸€èˆ¬çš„ã§ã™ã€‚ä»–ã«ç«¯ã®å€¤ã‚’ç¹°ã‚Šè¿”ã™æ–¹æ³•ãªã©ã‚‚ã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "\n",
    "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã£ã¦ã¯ã€å…ƒã®å…¥åŠ›ã®ã‚µã‚¤ã‚ºã‚’ä¿ã¤ã‚ˆã†ã«ã¨ã„ã†æŒ‡å®šã‚’ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®æ©Ÿèƒ½ã‚‚æŒãŸã›ã¦ãŠãã¨ä¾¿åˆ©ã§ã™ã€‚ãªãŠã€NumPyã«ã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã®é–¢æ•°ãŒå­˜åœ¨ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€å•é¡Œ6ã€‘ï¼ˆã‚¢ãƒ‰ãƒãƒ³ã‚¹èª²é¡Œï¼‰ãƒŸãƒ‹ãƒãƒƒãƒã¸ã®å¯¾å¿œ\n",
    "ã“ã“ã¾ã§ã®èª²é¡Œã¯ãƒãƒƒãƒã‚µã‚¤ã‚º1ã§è‰¯ã„ã¨ã—ã¦ãã¾ã—ãŸã€‚ã—ã‹ã—ã€å®Ÿéš›ã¯å…¨çµåˆå±¤åŒæ§˜ã«ãƒŸãƒ‹ãƒãƒƒãƒå­¦ç¿’ãŒè¡Œã‚ã‚Œã¾ã™ã€‚Conv1dã‚¯ãƒ©ã‚¹ã‚’è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ãŒåŒæ™‚ã«è¨ˆç®—ã§ãã‚‹ã‚ˆã†ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€å•é¡Œ7ã€‘ï¼ˆã‚¢ãƒ‰ãƒãƒ³ã‚¹èª²é¡Œï¼‰ä»»æ„ã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰æ•°\n",
    "ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ã¯1é™å®šã®å®Ÿè£…ã‚’ã—ã¦ãã¾ã—ãŸãŒã€ä»»æ„ã®ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰æ•°ã«å¯¾å¿œã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å•é¡Œï¼•ã€œï¼—ã®å›ç­”ã¯CNN1dã‚¯ãƒ©ã‚¹åŠã³Scratch1dCNNClassifierã‚¯ãƒ©ã‚¹å†…ã«è¨˜è¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã€å•é¡Œ8ã€‘å­¦ç¿’ã¨æ¨å®š\n",
    "\n",
    "ã“ã‚Œã¾ã§ä½¿ã£ã¦ããŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…¨çµåˆå±¤ã®ä¸€éƒ¨ã‚’Conv1dã«ç½®ãæ›ãˆã¦MNISTã‚’å­¦ç¿’ãƒ»æ¨å®šã—ã€Accuracyã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "\n",
    "å‡ºåŠ›å±¤ã ã‘ã¯å…¨çµåˆå±¤ã‚’ãã®ã¾ã¾ä½¿ã£ã¦ãã ã•ã„ã€‚ãŸã ã—ã€ãƒãƒ£ãƒ³ãƒãƒ«ãŒè¤‡æ•°ã‚ã‚‹çŠ¶æ…‹ã§ã¯å…¨çµåˆå±¤ã¸ã®å…¥åŠ›ã¯è¡Œãˆã¾ã›ã‚“ã€‚ãã®æ®µéšã§ã®ãƒãƒ£ãƒ³ãƒãƒ«ã¯1ã«ãªã‚‹ã‚ˆã†ã«ã™ã‚‹ã‹ã€ å¹³æ»‘åŒ– ã‚’è¡Œãªã£ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "\n",
    "ç”»åƒã«å¯¾ã—ã¦ã®1æ¬¡å…ƒç•³ã¿è¾¼ã¿ã¯å®Ÿç”¨ä¸Šã¯è¡Œã‚ãªã„ã“ã¨ã®ãŸã‚ã€ç²¾åº¦ã¯å•ã„ã¾ã›ã‚“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        pass    \n",
    "       \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X : æ¬¡ã®å½¢ã®ndarray, shape (batch_size, n_in_ch, n_features)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        \n",
    "        flatten_f = X.reshape(X.shape[0], -1)\n",
    "        \n",
    "        return flatten_f\n",
    "    \n",
    "    def backward(self,dA):\n",
    "        \"\"\"\n",
    "        dA : æ¬¡ã®å½¢ã®ndarray, shape (batch_size, n_features)\n",
    "        \n",
    "        \"\"\"\n",
    "        flatten_b = dA.reshape(self.X.shape[0], -1, self.X.shape[2])\n",
    "        \n",
    "        return flatten_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Connected Layer Class\n",
    "class FC:\n",
    "    \"\"\"\n",
    "   å…¨çµåˆå±¤\n",
    "    Parameters\n",
    "    ----------\n",
    "    initializer : åˆæœŸåŒ–æ–¹æ³•ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹\n",
    "    optimizer : æœ€é©åŒ–æ‰‹æ³•ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, layer):\n",
    "        self.optimizer = optimizer\n",
    "        self.layer = layer \n",
    "        # åˆæœŸåŒ–\n",
    "        # initializerã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ã„ã€self.Wã¨self.Bã‚’åˆæœŸåŒ–ã™ã‚‹\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2, None)\n",
    "        \n",
    "        self.HB = 0\n",
    "        self.HW = 0\n",
    "        \n",
    "    def forward(self, X): #X or Z\n",
    "        \"\"\"\n",
    "        ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : æ¬¡ã®å½¢ã®ndarray, shape (batch_size, n_nodes1)\n",
    "            å…¥åŠ›\n",
    "        Returns\n",
    "        ----------\n",
    "        A : æ¬¡ã®å½¢ã®ndarray, shape (batch_size, n_nodes2)\n",
    "            å‡ºåŠ›\n",
    "        \"\"\"        \n",
    "        self.X = X #X or Z\n",
    "\n",
    "        A = X @ self.W + self.B\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : æ¬¡ã®å½¢ã®ndarray, shape (batch_size, n_nodes2)\n",
    "            å¾Œã‚ã‹ã‚‰æµã‚Œã¦ããŸå‹¾é…\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : æ¬¡ã®å½¢ã®ndarray, shape (batch_size, n_nodes1)\n",
    "            å‰ã«æµã™å‹¾é…\n",
    "        \"\"\"\n",
    "        dB = np.sum(dA, axis=0) / self.layer.batch_size\n",
    "        dW = self.X.T @ dA / self.layer.batch_size\n",
    "        dZ = dA @ self.W.T\n",
    "        \n",
    "        self.dB = dB\n",
    "        self.dW = dW\n",
    "        \n",
    "\n",
    "        # æ›´æ–°\n",
    "        if self.layer.optimizer == \"SGD\":\n",
    "            self.B, self.W = self.optimizer.update(self)\n",
    "        elif self.layer.optimizer == \"AdaGrad\":\n",
    "            self.B, self.W, self.HB, self.HW = self.optimizer.update(self)\n",
    "            \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xavierã®åˆæœŸå€¤\n",
    "class XavierInitializer:\n",
    "    def W(self, n_in, n_out, fillter_size):\n",
    "        sigma = 1/np.sqrt(n_in)\n",
    "        if fillter_size == None:\n",
    "            W = sigma * np.random.randn(n_in, n_out) #é‡ã¿ã®åˆæœŸå€¤(å…¨çµåˆå±¤)\n",
    "        else:\n",
    "            W = sigma * np.random.randn(n_out, n_in, fillter_size) #é‡ã¿ã®åˆæœŸå€¤ï¼ˆç•³ã¿è¾¼ã¿å±¤ï¼‰\n",
    "        return W\n",
    "\n",
    "    def B(self, n_out):\n",
    "        sigma = 1/np.sqrt(n_out)\n",
    "        B = sigma * np.random.randn(n_out) #ãƒã‚¤ã‚¢ã‚¹ã®åˆæœŸå€¤\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heã®åˆæœŸå€¤\n",
    "class HeInitializer:\n",
    "    def W(self, n_in, n_out, fillter_size):\n",
    "        sigma = np.sqrt(2/n_in)\n",
    "        if fillter_size == None:\n",
    "            W = sigma * np.random.randn(n_in, n_out) #é‡ã¿ã®åˆæœŸå€¤(å…¨çµåˆå±¤)\n",
    "        else:\n",
    "            W = sigma * np.random.randn(n_out, n_in, fillter_size) #é‡ã¿ã®åˆæœŸå€¤ï¼ˆç•³ã¿è¾¼ã¿å±¤ï¼‰\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_out):\n",
    "        sigma = np.sqrt(2/n_out)\n",
    "        B = sigma * np.random.randn(n_out) #ãƒã‚¤ã‚¢ã‚¹ã®åˆæœŸå€¤\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    ç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : å­¦ç¿’ç‡\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ã‚ã‚‹å±¤ã®é‡ã¿ã‚„ãƒã‚¤ã‚¢ã‚¹ã®æ›´æ–°\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : æ›´æ–°å‰ã®å±¤ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹\n",
    "        \"\"\"\n",
    "        B = layer.B - (self.lr * layer.dB) \n",
    "        W = layer.W - (self.lr * layer.dW)\n",
    "        \n",
    "        return B, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ã‚ã‚‹å±¤ã®é‡ã¿ã‚„ãƒã‚¤ã‚¢ã‚¹ã®æ›´æ–°\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : æ›´æ–°å‰ã®å±¤ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹\n",
    "        \"\"\"\n",
    "        HB = layer.HB + layer.dB**2\n",
    "        B = layer.B - (self.lr * (1/(np.sqrt(HB) + 1e-7)) * layer.dB)\n",
    "\n",
    "        HW = layer.HW + layer.dW**2\n",
    "        W = layer.W - (self.lr * (1/(np.sqrt(HW) + 1e-7)) * layer.dW)\n",
    "        \n",
    "        return B, W, HB, HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        Z = 1 / (1 + np.exp(-A)) #ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°\n",
    "        self.A = A\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * ((1 - (1 / (1 + np.exp(-self.A)))) * (1 / (1 + np.exp(-self.A)))) #Aã«é–¢ã™ã‚‹æå¤±ã®å‹¾é…\n",
    "        return dA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        Z = np.tanh(A) #ãƒã‚¤ãƒ‘ãƒœãƒªãƒƒã‚¯ã‚¿ãƒ³ã‚¸ã‚§ãƒ³ãƒˆé–¢æ•°\n",
    "        self.A = A\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * (1 - np.tanh(self.A)**2) #Aã«é–¢ã™ã‚‹æå¤±ã®å‹¾é…\n",
    "        return dA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        Z = np.maximum(0 + 1e-7, A)\n",
    "        self.mask = (Z <= 0 + 1e-7)\n",
    "        return Z \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dZ[self.mask] = 0 + 1e-7\n",
    "        dA = dZ \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        A = A - np.max(A, axis=1, keepdims=True) #ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1, keepdims=True) #ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹é–¢æ•°\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, Z, Y):\n",
    "        dA = Z - Y  #Aã«é–¢ã™ã‚‹æå¤±ã®å‹¾é…\n",
    "        loss = -1 * np.sum(Y * np.log(Z + 1e-7)) / Z.shape[0] #äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®\n",
    "\n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch1dCNNClassifier:\n",
    "    def __init__(self, lr=10**-2, batch_size=20, activation_func=\"Tanh\", optimizer=\"AdaGrad\", \n",
    "                            n_pad=1, stride=2, fillter_size=3, n_fillter1=5, n_fillter2=10, n_epoch=1, verbose = False):\n",
    "        \n",
    "        self.lr = lr #å­¦ç¿’ç‡\n",
    "        self.batch_size = batch_size #ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "        self.activation_func = activation_func #æ´»æ€§åŒ–é–¢æ•°ã®ç¨®é¡\n",
    "        self.optimizer = optimizer #æœ€é©åŒ–æ‰‹æ³•\n",
    "        self.n_pad = n_pad #ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°æ•°\n",
    "        self.stride = stride #ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰æ•°\n",
    "        self.fillter_size = fillter_size #ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚µã‚¤ã‚º\n",
    "        self.n_fillter1 = n_fillter1 #1å±¤ç›®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ•°\n",
    "        self.n_fillter2 = n_fillter2 #2å±¤ç›®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ•°\n",
    "        self.n_epoch =n_epoch #ã‚¨ãƒãƒƒã‚¯æ•°\n",
    "        self.loss_list = [] #æå¤±ã‚’è¨˜éŒ²ã™ã‚‹ãƒªã‚¹ãƒˆ\n",
    "        self.loss_list_val = [] #æå¤±ã‚’è¨˜éŒ²ã™ã‚‹ãƒªã‚¹ãƒˆ(æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ç”¨)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def calc_out_shape(self, n_in, fillter_size, n_pad, stride):\n",
    "        n_out = int((n_in + 2*n_pad - fillter_size) / stride + 1)\n",
    "        return n_out\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, cnt = 1):\n",
    "        X = X.reshape(X.shape[0], -1, X.shape[1]) #2æ¬¡å…ƒâ†’3æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã¸reshape(ã‚µãƒ³ãƒ—ãƒ«æ•° :48000ã€ãƒãƒ£ãƒ³ãƒãƒ«æ•° :1ã€ç‰¹å¾´é‡æ•° :784)\n",
    "        self.n_features = X.shape[2]\n",
    "        self.n_in_ch = X.shape[1]\n",
    "        self.n_out1 = self.calc_out_shape(self.n_features, self.fillter_size, self.n_pad, self.stride)\n",
    "        self.n_out2 = self.calc_out_shape(self.n_out1, self.fillter_size, self.n_pad, self.stride)\n",
    "        self.n_output = y.shape[1]\n",
    "        if self.optimizer == \"SGD\":\n",
    "            optimizer = SGD(self.lr)\n",
    "        elif self.optimizer == \"AdaGrad\":\n",
    "            optimizer = AdaGrad(self.lr)\n",
    "        if self.activation_func == \"Tanh\":\n",
    "            activation = Tanh()\n",
    "            initializer = XavierInitializer() #Xavierã®åˆæœŸå€¤\n",
    "        elif self.activation_func == \"Sigmoid\":\n",
    "            activation = Sigmoid()\n",
    "            initializer = XavierInitializer() #Xavierã®åˆæœŸå€¤\n",
    "        elif self.activation_func == \"ReLU\":\n",
    "            activation = ReLU()\n",
    "            initializer = HeInitializer() #Heã®åˆæœŸå€¤\n",
    "        self.CNN1d1 = CNN1d(self.n_in_ch, self.n_fillter1, self.fillter_size, self.n_out1, initializer, optimizer, self)\n",
    "        self.activation1 = deepcopy(activation)\n",
    "        self.CNN1d2 = CNN1d(self.n_fillter1, self.n_fillter2, self.fillter_size, self.n_out2, initializer, optimizer, self)\n",
    "        self.activation2 = deepcopy(activation)\n",
    "        self.Flatten = Flatten()\n",
    "        self.FC3 = FC(self.n_out2*self.n_fillter2, self.n_output, initializer, optimizer, self)\n",
    "        self.activation3 = Softmax()\n",
    "         \n",
    "        #fitã‚’å†å¸°ã•ã›ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å…ˆã«æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã•ã›ã‚‹\n",
    "        if X_val is None:\n",
    "            get_mini_batch = GetMiniBatch(X, y, self.batch_size) #GetMiniBatchã‚¯ãƒ©ã‚¹ã§ãƒŸãƒ‹ãƒãƒƒãƒã‚’ä½œæˆ\n",
    "        else:\n",
    "            get_mini_batch = GetMiniBatch(X_val, y_val, self.batch_size) #GetMiniBatchã‚¯ãƒ©ã‚¹ã§ãƒŸãƒ‹ãƒãƒƒãƒã‚’ä½œæˆ\n",
    "        \n",
    "        #å­¦ç¿’å‡¦ç†\n",
    "        for i in range(self.n_epoch):\n",
    "            loss_list = []\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # ã“ã®foræ–‡å†…ã§ãƒŸãƒ‹ãƒãƒƒãƒãŒä½¿ãˆã‚‹\n",
    "\n",
    "                #forwardã®å‡¦ç†\n",
    "                A1 = self.CNN1d1.forward(mini_X_train)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                A2 = self.CNN1d2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                Z2_f = self.Flatten.forward(Z2)\n",
    "                A3 = self.FC3.forward(Z2_f)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "\n",
    "                #backwardã®å‡¦ç†\n",
    "                dA3, loss = self.activation3.backward(Z3, mini_y_train) # äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼èª¤å·®ã¨ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚’åˆã‚ã›ã¦ã„ã‚‹\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dZ2_f = self.Flatten.backward(dZ2)\n",
    "                dA2 = self.activation2.backward(dZ2_f)\n",
    "                dZ1 = self.CNN1d2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.CNN1d1.backward(dA1) # dZ0ã¯ä½¿ç”¨ã—ãªã„\n",
    "                \n",
    "                \"\"\"\n",
    "                Loss Curvã‚’æããŸã‚ã®å‡¦ç†\n",
    "                \"\"\"                \n",
    "                loss_list.append(loss)\n",
    "\n",
    "            \n",
    "            if X_val is None:\n",
    "                self.loss_list.append(np.mean(loss_list))\n",
    "                if self.verbose: #verboseã‚’Trueã«ã—ãŸéš›ã¯å­¦ç¿’éç¨‹ãªã©ã‚’å‡ºåŠ›ã™ã‚‹\n",
    "                    print(loss_list)\n",
    "            else:\n",
    "                self.loss_list_val.append(np.mean(loss_list))\n",
    "                if self.verbose: #verboseã‚’Trueã«ã—ãŸéš›ã¯å­¦ç¿’éç¨‹ãªã©ã‚’å‡ºåŠ›ã™ã‚‹\n",
    "                    print(loss_list_val)\n",
    "                \n",
    "        cnt += 1\n",
    "        if cnt == 3 or X_val is None:\n",
    "            return\n",
    "        \n",
    "        return self.fit(X, y, cnt = cnt) #æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯å†å¸°ã•ã›ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã•ã›ã‚‹ã€‚\n",
    "\n",
    "    def predict(self,X):\n",
    "        X = X.reshape(X.shape[0], -1, X.shape[1]) #2æ¬¡å…ƒâ†’3æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã¸reshape(ã‚µãƒ³ãƒ—ãƒ«æ•° :48000ã€ãƒãƒ£ãƒ³ãƒãƒ«æ•° :1ã€ç‰¹å¾´é‡æ•° :784)\n",
    "        A1 = self.CNN1d1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.CNN1d2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        Z2_f = self.Flatten.forward(Z2)\n",
    "        A3 = self.FC3.forward(Z2_f)\n",
    "        y = self.activation3.forward(A3)\n",
    "        \n",
    "        pred = np.argmax(y, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 10)\n",
      "(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.fit_transform(y_val[:, np.newaxis])\n",
    "print(y_train_one_hot.shape)\n",
    "print(y_val_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ãƒŸãƒ‹ãƒãƒƒãƒã‚’å–å¾—ã™ã‚‹ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : æ¬¡ã®å½¢ã®ndarray, shape (n_samples, n_features)\n",
    "      è¨“ç·´ãƒ‡ãƒ¼ã‚¿\n",
    "    y : æ¬¡ã®å½¢ã®ndarray, shape (n_samples, 1)\n",
    "      æ­£è§£å€¤\n",
    "    batch_size : int\n",
    "      ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "    seed : int\n",
    "      NumPyã®ä¹±æ•°ã®ã‚·ãƒ¼ãƒ‰\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1dc = Scratch1dCNNClassifier(lr=10**-1, batch_size=20, activation_func=\"ReLU\", optimizer=\"AdaGrad\", \n",
    "                            n_pad=1, stride=3, fillter_size=6, n_fillter1=2, n_fillter2=2, n_epoch=10, verbose = False)\n",
    "s1dc.fit(X_train, y_train_one_hot)#, X_val, y_val_one_hotã€è¨ˆç®—ã«æ™‚é–“ãŒæ›ã‹ã‚‹ç‚ºvalã¯ç„¡ã—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 6 6]\n",
      "æ­£è§£ç‡ï¼š0.83\n",
      "æ··åŒè¡Œåˆ—ï¼š\n",
      "[[ 899    1    9    6    5   18   26    2    6    8]\n",
      " [   1 1106    5    6    5    3    5    1    3    0]\n",
      " [  30   19  822   35   17    8   55   14   24    8]\n",
      " [   2    1   41  824   15   64   17   18   12   16]\n",
      " [  21    2   18   13  747   12   37   23   27   82]\n",
      " [  15    9   31   94   19  610   61    6   34   13]\n",
      " [  18    2   16    1   13   10  887    0   10    1]\n",
      " [   1   17   17    7   31   11    2  896    4   42]\n",
      " [  11    5   33  117   47   40   25   15  658   23]\n",
      " [  18    3    5   26   40    5    1   42   15  854]]\n",
      "classification_reportï¼š\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       980\n",
      "           1       0.95      0.97      0.96      1135\n",
      "           2       0.82      0.80      0.81      1032\n",
      "           3       0.73      0.82      0.77      1010\n",
      "           4       0.80      0.76      0.78       982\n",
      "           5       0.78      0.68      0.73       892\n",
      "           6       0.79      0.93      0.86       958\n",
      "           7       0.88      0.87      0.88      1028\n",
      "           8       0.83      0.68      0.74       974\n",
      "           9       0.82      0.85      0.83      1009\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.83      0.83      0.83     10000\n",
      "weighted avg       0.83      0.83      0.83     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "pred = s1dc.predict(X_test)\n",
    "print(pred)\n",
    "print(\"æ­£è§£ç‡ï¼š{:.2f}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"æ··åŒè¡Œåˆ—ï¼š\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"classification_reportï¼š\") #è©•ä¾¡ã‚’ã¾ã¨ã‚ã¦å‡ºåŠ›ã™ã‚‹ã‚„ã¤\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"model loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(1, len(s1dc.loss_list)+1), s1dc.loss_list, label=\"train_loss\", marker=\"o\", linewidth=3)\n",
    "plt.plot(np.arange(1, len(s1dc.loss_list_val)+1), s1dc.loss_list_val, label=\"val_loss\", marker=\"o\", linewidth=3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ï¼‘ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ã ãŒã€æ­£è§£ç‡ã¯0.83ã¨ãªã£ãŸã€‚å®Ÿè£…ã«foræ–‡ã‚’å¤šç”¨ã—ã¦ã—ã¾ã„è¨ˆç®—é€Ÿåº¦ãŒã‚ã¡ã‚ƒãã¡ã‚ƒé…ããªã£ã¦ã—ã¾ã£ãŸç‚ºã€è¤‡æ•°å›å®Ÿæ–½ã™ã‚‹ã“ã¨ãŒå‡ºæ¥ãªã‹ã£ãŸã€‚ä»Šå¾Œã¯ã€é­šæœ¬ã®ä¸­ã«ã‚ã‚‹ã€Œimage to columnã€ã®è€ƒãˆæ–¹ã‚’å®Ÿè£…ã«å–ã‚Šå…¥ã‚Œã€è¨ˆç®—é€Ÿåº¦ã®å‘ä¸Šã‚’å›³ã£ã¦è¡ŒããŸã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
