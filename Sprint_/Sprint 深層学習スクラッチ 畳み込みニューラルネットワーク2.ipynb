{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/takahashihideyuki/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】2次元畳み込み層の作成\n",
    "1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "$$\n",
    "a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}\n",
    "$$\n",
    "\n",
    "𝑎𝑖,𝑗,𝑚 : 出力される配列のi行j列、mチャンネルの値\n",
    "\n",
    "\n",
    "𝑖 : 配列の行方向のインデックス\n",
    "\n",
    "\n",
    "𝑗 : 配列の列方向のインデックス\n",
    "\n",
    "\n",
    "𝑚 : 出力チャンネルのインデックス\n",
    "\n",
    "\n",
    "𝐾 : 入力チャンネル数\n",
    "\n",
    "\n",
    "𝐹ℎ,𝐹𝑤 : 高さ方向（h）と幅方向（w）のフィルタのサイズ\n",
    "\n",
    "\n",
    "𝑥(𝑖+𝑠),(𝑗+𝑡),𝑘 : 入力の配列の(i+s)行(j+t)列、kチャンネルの値\n",
    "\n",
    "\n",
    "𝑤𝑠,𝑡,𝑘,𝑚 : 重みの配列のs行t列目。kチャンネルの入力に対して、mチャンネルへ出力する重み\n",
    "\n",
    "\n",
    "𝑏𝑚 : mチャンネルへの出力のバイアス項\n",
    "\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "\n",
    "次に更新式です。1次元畳み込み層や全結合層と同じ形です。\n",
    "\n",
    "$$\n",
    "w_{s,t,k,m}^{\\prime} = w_{s,t,k,m} - \\alpha \\frac{\\partial L}{\\partial w_{s,t,k,m}} \\\\\n",
    "b_{m}^{\\prime} = b_{m} - \\alpha \\frac{\\partial L}{\\partial b_{m}}\n",
    "$$\n",
    "\n",
    "𝛼 : 学習率\n",
    "\n",
    "\n",
    "∂𝐿∂𝑤𝑠,𝑡,𝑘,𝑚 : 𝑤𝑠,𝑡,𝑘,𝑚 に関する損失 𝐿 の勾配\n",
    "\n",
    "\n",
    "∂𝐿∂𝑏𝑚 : 𝑏𝑚 に関する損失 𝐿 の勾配\n",
    "\n",
    "\n",
    "勾配 ∂𝐿∂𝑤𝑠,𝑡,𝑘,𝑚 や ∂𝐿∂𝑏𝑚 を求めるためのバックプロパゲーションの数式が以下である。\n",
    "\n",
    "\n",
    "∂𝐿∂𝑤𝑠,𝑡,𝑘,𝑚=∑𝑖=0𝑁𝑜𝑢𝑡,ℎ−1∑𝑗=0𝑁𝑜𝑢𝑡,𝑤−1∂𝐿∂𝑎𝑖,𝑗,𝑚𝑥(𝑖+𝑠)(𝑗+𝑡),𝑘∂𝐿∂𝑏𝑚=∑𝑖=0𝑁𝑜𝑢𝑡,ℎ−1∑𝑗=0𝑁𝑜𝑢𝑡,𝑤−1∂𝐿∂𝑎𝑖,𝑗,𝑚\n",
    "\n",
    "∂𝐿∂𝑎𝑖 : 勾配の配列のi行j列、mチャンネルの値\n",
    "\n",
    "\n",
    "𝑁𝑜𝑢𝑡,ℎ,𝑁𝑜𝑢𝑡,𝑤 : 高さ方向（h）と幅方向（w）の出力のサイズ\n",
    "\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{s,t,k,m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1} \\frac{\\partial L}{\\partial a_{i,j,m}}x_{(i+s)(j+t),k}\\\\\n",
    "\\frac{\\partial L}{\\partial b_{m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1}\\frac{\\partial L}{\\partial a_{i,j,m}}\n",
    "$$\n",
    "\n",
    "∂𝐿∂𝑥𝑖,𝑗,𝑘 : 前の層に流す誤差の配列のi列j行、kチャンネルの値\n",
    "\n",
    "\n",
    "𝑀 : 出力チャンネル数\n",
    "\n",
    "\n",
    "ただし、 𝑖−𝑠<0 または 𝑖−𝑠>𝑁𝑜𝑢𝑡,ℎ−1 または 𝑗−𝑡<0 または 𝑗−𝑡>𝑁𝑜𝑢𝑡,𝑤−1 のとき ∂𝐿∂𝑎(𝑖−𝑠),(𝑗−𝑡),𝑚=0 です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2d:\n",
    "    def __init__(self, n_in_ch, n_filter, filter_h, filter_w, initializer, optimizer, layer):\n",
    "        self.n_in_ch = n_in_ch\n",
    "        self.B = initializer.B(n_filter)\n",
    "        self.W = initializer.W(n_in_ch, n_filter, filter_h, filter_w) \n",
    "        '''\n",
    "        self.W:\n",
    "        出力のshapeは(n_out_ch, n_in_ch, filter_h, filter_w)　\n",
    "        全結合層に合わせる為、引数はinとoutが逆転\n",
    "        '''\n",
    "        self.n_filter = n_filter\n",
    "        self.HB = 0\n",
    "        self.HW = 0\n",
    "        self.optimizer = optimizer\n",
    "        self.layer = layer\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X : 次の形のndarray, shape (batch_size, n_in_ch, n_in_h, n_in_w)\n",
    "        \n",
    "        W : 次の形のndarray, shape (n_out_ch, n_in_ch, filter_h, filter_w) #n_out_ch = n_filter\n",
    "        \n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        \n",
    "        batch_size, n_in_ch, n_in_h, n_in_w = X.shape\n",
    "        n_out_ch, n_in_ch, filter_h, filter_w = self.W.shape\n",
    "        \n",
    "        n_out_h, n_out_w = self.layer.calc_out_shape(n_in_h, n_in_w, filter_h, filter_w, self.layer.n_pad, self.layer.stride)\n",
    "        \n",
    "        col = np.zeros([n_out_h * n_out_w * batch_size, n_in_ch * filter_h * filter_w])\n",
    "        \n",
    "        self.n_out_h = n_out_h\n",
    "        self.n_out_w = n_out_w        \n",
    "        \n",
    "        #パディングの実装　（ゼロパディング処理）\n",
    "        X_pad = np.pad(X, [(0,0), (0,0), (self.layer.n_pad, self.layer.n_pad), (self.layer.n_pad, self.layer.n_pad)], 'constant', constant_values=0)\n",
    "\n",
    "        #im2col処理（DIC式）\n",
    "        for n in range(batch_size):\n",
    "            for i in range(n_out_h):\n",
    "                for j in range(n_out_w): \n",
    "                    patch = X_pad[n, : , i * self.layer.stride : i * self.layer.stride + filter_h, \n",
    "                                               j * self.layer.stride : j * self.layer.stride + filter_w]\n",
    "\n",
    "                    col[n * n_out_h *n_out_w + i * n_out_w + j, : ] = np.reshape(patch, -1)\n",
    "        \n",
    "        self.col = col\n",
    "        self.col_W = self.W.reshape(self.n_filter, -1).T\n",
    "        \n",
    "        out = self.col @ self.col_W + self.B\n",
    "            \n",
    "        A = out.reshape(batch_size, n_out_h, n_out_w, -1).transpose(0, 3, 1, 2)\n",
    "   \n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        #col2im処理（魚本式）\n",
    "        \n",
    "        n_out_ch, n_in_ch, filter_h, filter_w = self.W.shape\n",
    "        dA = dA.transpose(0,2,3,1).reshape(-1, n_out_ch)\n",
    "\n",
    "        dB = np.sum(dA, axis=0) / self.layer.batch_size\n",
    "        dW = self.col.T @ dA\n",
    "        dW = dW.transpose(1, 0).reshape(n_out_ch, n_in_ch, filter_h, filter_w) / self.layer.batch_size\n",
    "\n",
    "        dcol = dA @ self.col_W.T\n",
    "        \n",
    "        batch_size, n_in_ch, n_in_h, n_in_w = self.X.shape\n",
    "        \n",
    "        dcol = dcol.reshape(batch_size, self.n_out_h, self.n_out_w, n_in_ch, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "        \n",
    "        img = np.zeros((batch_size, n_in_ch, n_in_h + 2*self.layer.n_pad + self.layer.stride - 1, n_in_w + 2*self.layer.n_pad + self.layer.stride - 1))\n",
    "        for y in range(filter_h):\n",
    "            y_max = y + self.layer.stride * self.n_out_h\n",
    "            for x in range(filter_w):\n",
    "                x_max = x + self.layer.stride * self.n_out_w\n",
    "                img[:, :, y:y_max:self.layer.stride, x:x_max:self.layer.stride] += dcol[:, :, y, x, :, :]\n",
    "\n",
    "        dX=  img[:, :, self.layer.n_pad : n_in_h + self.layer.n_pad, self.layer.n_pad : n_in_w + self.layer.n_pad]\n",
    "        \n",
    "        \n",
    "        self.dB = dB\n",
    "        self.dW = dW\n",
    "        \n",
    "        \n",
    "        # 更新\n",
    "        if self.layer.optimizer == \"SGD\":\n",
    "            self.B, self.W = self.optimizer.update(self)\n",
    "        elif self.layer.optimizer == \"AdaGrad\":\n",
    "            self.B, self.W, self.HB, self.HW = self.optimizer.update(self)\n",
    "\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】2次元畳み込み後の出力サイズ\n",
    "畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。\n",
    "\n",
    "$$\n",
    "N_{h,out} =  \\frac{N_{h,in}+2P_{h}-F_{h}}{S_{h}} + 1\\\\\n",
    "N_{w,out} =  \\frac{N_{w,in}+2P_{w}-F_{w}}{S_{w}} + 1\n",
    "$$\n",
    "\n",
    "𝑁𝑜𝑢𝑡 : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "𝑁𝑖𝑛 : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "𝑃 : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "𝐹 : フィルタのサイズ\n",
    "\n",
    "\n",
    "𝑆 : ストライドのサイズ\n",
    "\n",
    "\n",
    "ℎ が高さ方向、 𝑤 が幅方向である"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_out_shape(self, n_in_h, n_in_w, fillter_h, fillter_w, n_pad, stride):\n",
    "    n_out_h = int((n_in_h + 2*n_pad - fillter_h) / stride + 1)\n",
    "    \n",
    "    n_out_w = int((n_in_w + 2*n_pad - fillter_w) / stride + 1)\n",
    "    \n",
    "    return n_out_h, n_out_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】最大プーリング層の作成\n",
    "最大プーリング層のクラスMaxPool2Dを作成してください。プーリング層は数式で表さない方が分かりやすい部分もありますが、数式で表すとフォワードプロパゲーションは以下のようになります。\n",
    "\n",
    "$$\n",
    "a_{i,j,k} = \\max_{(p,q)\\in P_{i,j}}x_{p,q,k}\n",
    "$$\n",
    "\n",
    "𝑃𝑖,𝑗 : i行j列への出力する場合の入力配列のインデックスの集合。 𝑆ℎ×𝑆𝑤 の範囲内の行（p）と列（q）\n",
    "\n",
    "\n",
    "𝑆ℎ,𝑆𝑤 : 高さ方向（h）と幅方向（w）のストライドのサイズ\n",
    "\n",
    "\n",
    "(𝑝,𝑞)∈𝑃𝑖,𝑗 : 𝑃𝑖,𝑗 に含まれる行（p）と列（q）のインデックス\n",
    "\n",
    "\n",
    "𝑎𝑖,𝑗,𝑚 : 出力される配列のi行j列、kチャンネルの値\n",
    "\n",
    "\n",
    "𝑥𝑝,𝑞,𝑘 : 入力の配列のp行q列、kチャンネルの値\n",
    "\n",
    "\n",
    "ある範囲の中でチャンネル方向の軸は残したまま最大値を計算することになります。\n",
    "\n",
    "\n",
    "バックプロパゲーションのためには、フォワードプロパゲーションのときの最大値のインデックス (𝑝,𝑞) を保持しておく必要があります。フォワード時に最大値を持っていた箇所にそのままの誤差を流し、そこ以外には0を入れるためです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, pool_h, pool_w, pool_stride, pool_pad, layer):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.pool_stride = pool_stride\n",
    "        self.pool_pad = pool_pad\n",
    "        self.layer = layer\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        batch_size, n_in_ch, n_in_h, n_in_w = X.shape\n",
    "        n_out_h, n_out_w = self.layer.calc_out_shape(n_in_h, n_in_w, self.pool_h, self.pool_w, self.pool_pad, self.pool_stride)    \n",
    "        \n",
    "        img = np.pad(X, [(0,0), (0,0), (self.pool_pad, self.pool_pad), (self.pool_pad, self.pool_pad)], 'constant') #プーリングでは無し＝０\n",
    "        col = np.zeros((batch_size, n_in_ch, self.pool_h, self.pool_w, n_out_h, n_out_w))\n",
    "        \n",
    "\n",
    "        #im2col処理(魚本式)\n",
    "        for y in range(self.pool_h):\n",
    "            y_max = y + self.pool_stride*n_out_h\n",
    "            for x in range(self.pool_w):\n",
    "                x_max = x + self.pool_stride*n_out_w\n",
    "                col[:, :, y, x, :, :] = img[:, :, y:y_max:self.pool_stride, x:x_max:self.pool_stride]\n",
    "\n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(batch_size*n_out_h*n_out_w, -1)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "        \n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        pool_out_f = out.reshape(batch_size, n_out_h, n_out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        self.n_out_h = n_out_h\n",
    "        self.n_out_w = n_out_w\n",
    "        \n",
    "        self.X = X\n",
    "        self.arg_max = arg_max\n",
    "        \n",
    "        return pool_out_f\n",
    "    \n",
    "    \n",
    "    def backward(self, Z):\n",
    "        #col2im処理（魚本式）\n",
    "        batch_size, n_in_ch, n_in_h, n_in_w = self.X.shape\n",
    "        \n",
    "        Z = Z.transpose(0,2,3,1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        \n",
    "        dmax = np.zeros((Z.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = Z.flatten()\n",
    "        dmax = dmax.reshape(Z.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1) \n",
    "        \n",
    "        dcol = dcol.reshape(batch_size, self.n_out_h, self.n_out_w, n_in_ch, self.pool_h, self.pool_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "        \n",
    "        img = np.zeros((batch_size, n_in_ch, n_in_h + 2*self.pool_pad + self.pool_stride - 1, n_in_w + 2*self.pool_pad + self.pool_stride - 1))\n",
    "        for y in range(self.pool_h):\n",
    "            y_max = y + self.pool_stride * self.n_out_h\n",
    "            for x in range(self.pool_w):\n",
    "                x_max = x + self.pool_stride * self.n_out_w\n",
    "\n",
    "                img[:, :, y:y_max:self.pool_stride, x:x_max:self.pool_stride] += dcol[:, :, y, x, :, :]\n",
    "\n",
    "        pool_out_b =  img[:, :, self.pool_pad : n_in_h + self.pool_pad, self.pool_pad : n_in_w + self.pool_pad]        \n",
    "        \n",
    "        return pool_out_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  【問題4】（アドバンス課題）平均プーリングの作成\n",
    "平均プーリング層のクラスAveragePool2Dを作成してください。\n",
    "\n",
    "範囲内の最大値ではなく、平均値を出力とするプーリング層です。\n",
    "\n",
    "画像認識関係では最大プーリング層が一般的で、平均プーリングはあまり使われません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragePool2D:\n",
    "    def __init__(self, pool_h, pool_w, pool_stride, pool_pad, layer):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.pool_stride = pool_stride\n",
    "        self.pool_pad = pool_pad\n",
    "        self.layer = layer\n",
    "    \n",
    "    def forward(self, X):\n",
    "        print(X.shape)\n",
    "        \n",
    "        batch_size, n_in_ch, n_in_h, n_in_w = X.shape\n",
    "        \n",
    "        n_out_h, n_out_w = self.layer.calc_out_shape(n_in_h, n_in_w, self.pool_h, self.pool_w, self.pool_pad, self.pool_stride)    \n",
    "        \n",
    "        img = np.pad(X, [(0,0), (0,0), (self.pool_pad, self.pool_pad), (self.pool_pad, self.pool_pad)], 'constant') #プーリングでは無し＝０\n",
    "        col = np.zeros((batch_size, n_in_ch, self.pool_h, self.pool_w, n_out_h, n_out_w))\n",
    "        \n",
    "\n",
    "        #im2col処理(魚本式)\n",
    "        for y in range(self.pool_h):\n",
    "            y_max = y + self.pool_stride*n_out_h\n",
    "            for x in range(self.pool_w):\n",
    "                x_max = x + self.pool_stride*n_out_w\n",
    "                col[:, :, y, x, :, :] = img[:, :, y:y_max:self.pool_stride, x:x_max:self.pool_stride]\n",
    "\n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(batch_size*n_out_h*n_out_w, -1)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "        \n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.average(col, axis=1)\n",
    "        pool_out_f = out.reshape(batch_size, n_out_h, n_out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        self.n_out_h = n_out_h\n",
    "        self.n_out_w = n_out_w\n",
    "        \n",
    "        self.X = X\n",
    "        self.arg_max = arg_max\n",
    "        \n",
    "        print(pool_out_f.shape)\n",
    "        \n",
    "        return pool_out_f\n",
    "    \n",
    "    \n",
    "    def backward(self, Z):\n",
    "        #col2im処理（魚本式）\n",
    "        batch_size, n_in_ch, n_in_h, n_in_w = self.X.shape\n",
    "        print(batch_size, n_in_ch, n_in_h, n_in_w)\n",
    "        \n",
    "        Z = Z.transpose(0,2,3,1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        \n",
    "        dmax = np.zeros((Z.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = Z.flatten()\n",
    "        dmax = dmax.reshape(Z.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1) \n",
    "        \n",
    "        dcol = dcol.reshape(batch_size, self.n_out_h, self.n_out_w, n_in_ch, self.pool_h, self.pool_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "        \n",
    "        img = np.zeros((batch_size, n_in_ch, n_in_h + 2*self.pool_pad + self.pool_stride - 1, n_in_w + 2*self.pool_pad + self.pool_stride - 1))\n",
    "        for y in range(self.pool_h):\n",
    "            y_max = y + self.pool_stride * self.n_out_h\n",
    "            for x in range(self.pool_w):\n",
    "                x_max = x + self.pool_stride * self.n_out_w\n",
    "                \n",
    "                print(img.shape)\n",
    "                print(dcol.shape)\n",
    "                img[:, :, y:y_max:self.pool_stride, x:x_max:self.pool_stride] += dcol[:, :, y, x, :, :]\n",
    "\n",
    "        pool_out_b =  img[:, :, self.pool_pad : n_in_h + self.pool_pad, self.pool_pad : n_in_w + self.pool_pad]        \n",
    "        \n",
    "        return pool_out_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  【問題5】平滑化\n",
    "平滑化するためのFlattenクラスを作成してください。\n",
    "\n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。\n",
    "\n",
    "この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        pass    \n",
    "       \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        X : 次の形のndarray, shape (batch_size, n_in_ch, n_in_h, n_in_w)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.X_shape = X.shape\n",
    "        \n",
    "        flatten_f = X.reshape(X.shape[0], -1)\n",
    "        \n",
    "        return flatten_f\n",
    "    \n",
    "    def backward(self,dA):\n",
    "        \"\"\"\n",
    "        dA : 次の形のndarray, shape (batch_size, n_features)\n",
    "        \n",
    "        \"\"\"\n",
    "        flatten_b = dA.reshape(self.X_shape)\n",
    "        \n",
    "        return flatten_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】学習と推定\n",
    "作成したConv2dを使用してMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "精度は低くともまずは動くことを目指してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Connected Layer Class\n",
    "class FC:\n",
    "    \"\"\"\n",
    "   全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, layer):\n",
    "        self.optimizer = optimizer\n",
    "        self.layer = layer \n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2, None, None)\n",
    "        \n",
    "        self.HB = 0\n",
    "        self.HW = 0\n",
    "        \n",
    "    def forward(self, X): #X or Z\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"        \n",
    "        self.X = X #X or Z\n",
    "\n",
    "        A = X @ self.W + self.B\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dB = np.sum(dA, axis=0) / self.layer.batch_size\n",
    "        dW = self.X.T @ dA / self.layer.batch_size\n",
    "        dZ = dA @ self.W.T\n",
    "        \n",
    "        self.dB = dB\n",
    "        self.dW = dW\n",
    "        \n",
    "\n",
    "        # 更新\n",
    "        if self.layer.optimizer == \"SGD\":\n",
    "            self.B, self.W = self.optimizer.update(self)\n",
    "        elif self.layer.optimizer == \"AdaGrad\":\n",
    "            self.B, self.W, self.HB, self.HW = self.optimizer.update(self)\n",
    "            \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xavierの初期値\n",
    "class XavierInitializer:\n",
    "    def W(self, n_in, n_out, filter_h, filter_w):\n",
    "        sigma = 1/np.sqrt(n_in)\n",
    "        if filter_h is None:\n",
    "            W = sigma * np.random.randn(n_in, n_out) #重みの初期値(全結合層)\n",
    "        else:\n",
    "            W = sigma * np.random.randn(n_out, n_in, filter_h, filter_w) #重みの初期値（畳み込み層）\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_out):\n",
    "        sigma = 1/np.sqrt(n_out)\n",
    "        B = sigma * np.random.randn(n_out) #バイアスの初期値\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heの初期値\n",
    "class HeInitializer:\n",
    "    def W(self, n_in, n_out, filter_h, filter_w):\n",
    "        sigma = np.sqrt(2/n_in)\n",
    "        if filter_h is None:\n",
    "            W = sigma * np.random.randn(n_in, n_out) #重みの初期値(全結合層)\n",
    "        else:\n",
    "            W = sigma * np.random.randn(n_out, n_in, filter_h, filter_w) #重みの初期値（畳み込み層）\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_out):\n",
    "        sigma = np.sqrt(2/n_out)\n",
    "        B = sigma * np.random.randn(n_out) #バイアスの初期値\n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        B = layer.B - (self.lr * layer.dB) \n",
    "        W = layer.W - (self.lr * layer.dW)\n",
    "        \n",
    "        return B, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        HB = layer.HB + layer.dB**2\n",
    "        B = layer.B - (self.lr * (1/(np.sqrt(HB) + 1e-7)) * layer.dB)\n",
    "\n",
    "        HW = layer.HW + layer.dW**2\n",
    "        W = layer.W - (self.lr * (1/(np.sqrt(HW) + 1e-7)) * layer.dW)\n",
    "        \n",
    "        return B, W, HB, HW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        Z = 1 / (1 + np.exp(-A)) #シグモイド関数\n",
    "        self.A = A\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * ((1 - (1 / (1 + np.exp(-self.A)))) * (1 / (1 + np.exp(-self.A)))) #Aに関する損失の勾配\n",
    "        return dA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        Z = np.tanh(A) #ハイパボリックタンジェント関数\n",
    "        self.A = A\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dA = dZ * (1 - np.tanh(self.A)**2) #Aに関する損失の勾配\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        Z = np.maximum(0 + 1e-7, A)\n",
    "        self.mask = (Z <= 0 + 1e-7)\n",
    "        return Z \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        dZ[self.mask] = 0 + 1e-7\n",
    "        dA = dZ \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, A):\n",
    "        A = A - np.max(A, axis=1, keepdims=True) #オーバーフロー対策\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1, keepdims=True) #ソフトマックス関数\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, Z, Y):\n",
    "        dA = Z - Y  #Aに関する損失の勾配\n",
    "        loss = -1 * np.sum(Y * np.log(Z + 1e-7)) / Z.shape[0] #交差エントロピー誤差\n",
    "\n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch2dCNNClassifier:\n",
    "    def __init__(self, lr=10**-2, batch_size=20, activation_func=\"ReLU\", optimizer=\"AdaGrad\", pooling=\"MaxPool2D\", pool_h_w_stride=2,\n",
    "                            n_pad=1, stride=2, filter_h=3, filter_w=3, n_filter1=2, n_filter2=2, n_epoch=1, verbose = False):\n",
    "        \n",
    "        self.lr = lr #学習率\n",
    "        self.batch_size = batch_size #バッチサイズ\n",
    "        self.activation_func = activation_func #活性化関数の種類\n",
    "        self.optimizer = optimizer #最適化手法\n",
    "        self.pooling = pooling #プーリング方法\n",
    "        self.pool_h = pool_h_w_stride #poolingウィンドウ縦\n",
    "        self.pool_w = pool_h_w_stride #poolingウィンドウ横\n",
    "        self.pool_stride = pool_h_w_stride #poolingストライド\n",
    "        self.n_pad = n_pad #パディング数\n",
    "        self.stride = stride #ストライド数\n",
    "        self.filter_h = filter_h #フィルター縦   \n",
    "        self.filter_w = filter_w #フィルター横\n",
    "        self.n_filter1 = n_filter1 #1層目フィルター数\n",
    "        self.n_filter2 = n_filter2 #2層目フィルター数\n",
    "        self.n_epoch =n_epoch #エポック数\n",
    "        self.loss_list = [] #損失を記録するリスト\n",
    "        self.loss_list_val = [] #損失を記録するリスト(検証データ用)\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def calc_out_shape(self, n_in_h, n_in_w, filter_h, filter_w, n_pad, stride):\n",
    "        n_out_h = int((n_in_h + 2*n_pad - filter_h) // stride + 1)\n",
    "        n_out_w = int((n_in_w + 2*n_pad - filter_w) // stride + 1)\n",
    "        return n_out_h, n_out_w    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, cnt = 1):\n",
    "        batch_size, n_in_ch, n_in_h, n_in_w = X.shape\n",
    "        n_out_h1, n_out_w1 = self.calc_out_shape(n_in_h, n_in_w, self.filter_h, self.filter_w, self.n_pad, self.stride)\n",
    "        n_out_h1_p, n_out_w1_p = self.calc_out_shape(n_out_h1, n_out_w1, self.pool_h, self.pool_w, 0, self.pool_stride) \n",
    "        n_out_h2, n_out_w2 = self.calc_out_shape(n_out_h1_p, n_out_w1_p, self.filter_h, self.filter_w, self.n_pad, self.stride)\n",
    "        n_out_h2_p, n_out_w2_p = self.calc_out_shape(n_out_h2, n_out_w2, self.pool_h, self.pool_w, 0, self.pool_stride) \n",
    "        n_output = y.shape[1]\n",
    "        if self.optimizer == \"SGD\":\n",
    "            optimizer = SGD(self.lr)\n",
    "        elif self.optimizer == \"AdaGrad\":\n",
    "            optimizer = AdaGrad(self.lr)\n",
    "        if self.activation_func == \"Tanh\":\n",
    "            activation = Tanh()\n",
    "            initializer = XavierInitializer() #Xavierの初期値\n",
    "        elif self.activation_func == \"Sigmoid\":\n",
    "            activation = Sigmoid()\n",
    "            initializer = XavierInitializer() #Xavierの初期値\n",
    "        elif self.activation_func == \"ReLU\":\n",
    "            activation = ReLU()\n",
    "            initializer = HeInitializer() #Heの初期値\n",
    "        if self.pooling == \"MaxPool2D\":\n",
    "            pooling = MaxPool2D(self.pool_h, self.pool_w, self.pool_stride, 0, self)\n",
    "        elif self.pooing == \"AveragePool2D\":\n",
    "            pooling = AveragePool2D(self.pool_h, self.pool_w, self.pool_stride, 0, self)\n",
    "        self.CNN2d1 = CNN2d(n_in_ch, self.n_filter1, self.filter_h, self.filter_w, initializer, optimizer, self)\n",
    "        self.activation1 = deepcopy(activation)\n",
    "        self.pooling1 = deepcopy(pooling)\n",
    "        self.CNN2d2 = CNN2d(self.n_filter1, self.n_filter2, self.filter_h, self.filter_w, initializer, optimizer, self)\n",
    "        self.activation2 = deepcopy(activation)\n",
    "        self.pooling2 = deepcopy(pooling)\n",
    "        self.Flatten = Flatten()\n",
    "        self.FC3 = FC(n_out_h2_p*n_out_w2_p*self.n_filter2, n_output, initializer, optimizer, self)\n",
    "        self.activation3 = Softmax()\n",
    "         \n",
    "        #fitを再帰させて学習データと検証データの両方を学習させる。検証データがあれば先に検証データを学習させる\n",
    "        if X_val is None:\n",
    "            get_mini_batch = GetMiniBatch(X, y, self.batch_size) #GetMiniBatchクラスでミニバッチを作成\n",
    "        else:\n",
    "            get_mini_batch = GetMiniBatch(X_val, y_val, self.batch_size) #GetMiniBatchクラスでミニバッチを作成\n",
    "        \n",
    "        #学習処理\n",
    "        for i in range(self.n_epoch):\n",
    "            loss_list = []\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # このfor文内でミニバッチが使える\n",
    "\n",
    "                #forwardの処理\n",
    "                A1 = self.CNN2d1.forward(mini_X_train)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                Z1_p = self.pooling1.forward(Z1)\n",
    "                A2 = self.CNN2d2.forward(Z1_p)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                Z2_p = self.pooling2.forward(Z2)\n",
    "                Z2_f = self.Flatten.forward(Z2_p)\n",
    "                A3 = self.FC3.forward(Z2_f)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                \n",
    "                #backwardの処理\n",
    "                dA3, loss = self.activation3.backward(Z3, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dZ2_f = self.Flatten.backward(dZ2)\n",
    "                dZ2_p = self.pooling2.backward(dZ2_f)\n",
    "                dA2 = self.activation2.backward(dZ2_p)\n",
    "                dZ1 = self.CNN2d2.backward(dA2)\n",
    "                dZ1_p = self.pooling1.backward(dZ1)\n",
    "                dA1 = self.activation1.backward(dZ1_p)\n",
    "                dZ0 = self.CNN2d1.backward(dA1) # dZ0は使用しない\n",
    "                \n",
    "                \"\"\"\n",
    "                Loss Curvを描くための処理\n",
    "                \"\"\"                \n",
    "                loss_list.append(loss)\n",
    "\n",
    "            \n",
    "            if X_val is None:\n",
    "                self.loss_list.append(np.mean(loss_list))\n",
    "                if self.verbose: #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_list)\n",
    "            else:\n",
    "                self.loss_list_val.append(np.mean(loss_list))\n",
    "                if self.verbose: #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_list_val)\n",
    "                \n",
    "        cnt += 1\n",
    "        if cnt == 3 or X_val is None:\n",
    "            return\n",
    "        \n",
    "        return self.fit(X, y, cnt = cnt) #検証データが入力されている場合は再帰させて学習データを学習させる。\n",
    "\n",
    "    def predict(self,X):\n",
    "        A1 = self.CNN2d1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        Z1_p = self.pooling1.forward(Z1)\n",
    "        A2 = self.CNN2d2.forward(Z1_p)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        Z2_p = self.pooling1.forward(Z2)\n",
    "        Z2_f = self.Flatten.forward(Z2_p)\n",
    "        A3 = self.FC3.forward(Z2_f)\n",
    "        y = self.activation3.forward(A3)\n",
    "        \n",
    "        print(y)\n",
    "        \n",
    "        pred = np.argmax(y, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#説明変数へchの次元を追加。４次元にreshape(N, C, H, W)。\n",
    "X_train = X_train.reshape(X_train.shape[0], -1, X_train.shape[1], X_train.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], -1, X_test.shape[1], X_test.shape[2])\n",
    "\n",
    "#正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "#学習データを学習データと検証データに分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "#目的変数をone-hot処理\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.fit_transform(y_val[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2dc = Scratch2dCNNClassifier(lr=10**-1, batch_size=20, activation_func=\"ReLU\", optimizer=\"AdaGrad\", pooling=\"MaxPool2D\", pool_h_w_stride=2,\n",
    "                            n_pad=1, stride=2, filter_h=3, filter_w=3, n_filter1=100, n_filter2=50, n_epoch=10, verbose = False)\n",
    "s2dc.fit(X_train, y_train_one_hot, X_val, y_val_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.60862534e-09 2.35272617e-07 1.04344983e-06 ... 9.99998141e-01\n",
      "  1.07505271e-11 3.35351229e-07]\n",
      " [4.46727941e-05 1.17107576e-03 9.98784212e-01 ... 1.43208904e-08\n",
      "  1.54712601e-10 1.04923860e-14]\n",
      " [1.96725700e-07 9.99977405e-01 1.70186677e-06 ... 1.10666412e-05\n",
      "  6.06700069e-09 4.31265769e-08]\n",
      " ...\n",
      " [5.92208504e-10 1.10302377e-08 2.44987408e-10 ... 5.33054338e-07\n",
      "  3.21894770e-08 2.66764245e-06]\n",
      " [8.65516820e-10 1.00930538e-10 3.01901882e-11 ... 3.59804291e-10\n",
      "  1.79370745e-05 5.69434673e-07]\n",
      " [2.80690897e-07 6.42641024e-10 2.45780314e-06 ... 6.94447464e-11\n",
      "  2.32676222e-07 2.41303400e-08]]\n",
      "正解率：0.97\n",
      "混同行列：\n",
      "[[ 958    2    8    0    1    1    6    1    2    1]\n",
      " [   0 1128    4    1    0    0    1    0    0    1]\n",
      " [   1    3 1010    2    2    0    1    6    6    1]\n",
      " [   0    0   10  980    0    7    0    8    3    2]\n",
      " [   0    0    3    0  969    1    0    1    2    6]\n",
      " [   0    0    0   23    1  857    3    3    1    4]\n",
      " [   8    4    2    0    5    4  928    0    7    0]\n",
      " [   0    4   18    4    2    0    0  985    1   14]\n",
      " [   6    1    9   10    3    4    8    3  922    8]\n",
      " [   2    1    3    4   16    1    0   11    7  964]]\n",
      "classification_report：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.95      0.98      0.96      1032\n",
      "           3       0.96      0.97      0.96      1010\n",
      "           4       0.97      0.99      0.98       982\n",
      "           5       0.98      0.96      0.97       892\n",
      "           6       0.98      0.97      0.97       958\n",
      "           7       0.97      0.96      0.96      1028\n",
      "           8       0.97      0.95      0.96       974\n",
      "           9       0.96      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#テストデータ\n",
    "pred = s2dc.predict(X_test)\n",
    "print(\"正解率：{:.2f}\".format(accuracy_score(y_test, pred)))\n",
    "print(\"混同行列：\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(\"classification_report：\") #評価をまとめて出力するやつ\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"model loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(1, len(s2dc.loss_list)+1), s2dc.loss_list, label=\"train_loss\", marker=\"o\", linewidth=3)\n",
    "plt.plot(np.arange(1, len(s2dc.loss_list_val)+1), s2dc.loss_list_val, label=\"val_loss\", marker=\"o\", linewidth=3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "覚書：https://teratail.com/questions/257543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】（アドバンス課題）LeNet\n",
    "CNNで画像認識を行う際は、フィルタサイズや層の数などを１から考えるのではなく、有名な構造を利用することが一般的です。現在では実用的に使われることはありませんが、歴史的に重要なのは1998年の LeNet です。この構造を再現してMNISTに対して動かし、Accuracyを計算してください。\n",
    "\n",
    "サブサンプリングとは現在のプーリングに相当するものです。現代風に以下のように作ってみることにします。活性化関数も当時はシグモイド関数ですが、ReLUとします。\n",
    "\n",
    "\n",
    "1. 畳み込み層　出力チャンネル数6、フィルタサイズ5×5、ストライド1\n",
    "2. ReLU\n",
    "3. 最大プーリング\n",
    "4. 畳み込み層　出力チャンネル数16、フィルタサイズ5×5、ストライド1\n",
    "5. ReLU\n",
    "6. 最大プーリング\n",
    "7. 平滑化\n",
    "8. 全結合層　出力ノード数120\n",
    "9. ReLU\n",
    "10. 全結合層　出力ノード数84\n",
    "11. ReLU\n",
    "12. 全結合層　出力ノード数10\n",
    "13. ソフトマックス関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch2dLeNet:\n",
    "    def __init__(self, lr=10**-2, batch_size=20, activation_func=\"ReLU\", optimizer=\"AdaGrad\", pooling=\"MaxPool2D\", pool_h_w_stride=2,\n",
    "                            n_pad=1, stride=1, filter_h=5, filter_w=5, n_filter1=6, n_filter2=16, n_node3=120, n_node4=84, n_epoch=1, verbose = False):\n",
    "        \n",
    "        self.lr = lr #学習率\n",
    "        self.batch_size = batch_size #バッチサイズ\n",
    "        self.activation_func = activation_func #活性化関数の種類\n",
    "        self.optimizer = optimizer #最適化手法\n",
    "        self.pooling = pooling #プーリング方法\n",
    "        self.pool_h = pool_h_w_stride #poolingウィンドウ縦\n",
    "        self.pool_w = pool_h_w_stride #poolingウィンドウ横\n",
    "        self.pool_stride = pool_h_w_stride #poolingストライド\n",
    "        self.n_pad = n_pad #パディング数\n",
    "        self.stride = stride #ストライド数\n",
    "        self.filter_h = filter_h #フィルター縦   \n",
    "        self.filter_w = filter_w #フィルター横\n",
    "        self.n_filter1 = n_filter1 #1層目フィルター数\n",
    "        self.n_filter2 = n_filter2 #2層目フィルター数\n",
    "        self.n_node3 = n_node3 #3層目ノード数\n",
    "        self.n_node4 = n_node4 #4層目ノード数\n",
    "        self.n_epoch =n_epoch #エポック数\n",
    "        self.loss_list = [] #損失を記録するリスト\n",
    "        self.loss_list_val = [] #損失を記録するリスト(検証データ用)\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def calc_out_shape(self, n_in_h, n_in_w, filter_h, filter_w, n_pad, stride):\n",
    "        n_out_h = int((n_in_h + 2*n_pad - filter_h) // stride + 1)\n",
    "        n_out_w = int((n_in_w + 2*n_pad - filter_w) // stride + 1)\n",
    "        return n_out_h, n_out_w    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None, cnt = 1):\n",
    "        batch_size, n_in_ch, n_in_h, n_in_w = X.shape\n",
    "        n_out_h1, n_out_w1 = self.calc_out_shape(n_in_h, n_in_w, self.filter_h, self.filter_w, self.n_pad, self.stride)\n",
    "        n_out_h1_p, n_out_w1_p = self.calc_out_shape(n_out_h1, n_out_w1, self.pool_h, self.pool_w, 0, self.pool_stride) \n",
    "        n_out_h2, n_out_w2 = self.calc_out_shape(n_out_h1_p, n_out_w1_p, self.filter_h, self.filter_w, self.n_pad, self.stride)\n",
    "        n_out_h2_p, n_out_w2_p = self.calc_out_shape(n_out_h2, n_out_w2, self.pool_h, self.pool_w, 0, self.pool_stride) \n",
    "        n_output = y.shape[1]\n",
    "        if self.optimizer == \"SGD\":\n",
    "            optimizer = SGD(self.lr)\n",
    "        elif self.optimizer == \"AdaGrad\":\n",
    "            optimizer = AdaGrad(self.lr)\n",
    "        if self.activation_func == \"Tanh\":\n",
    "            activation = Tanh()\n",
    "            initializer = XavierInitializer() #Xavierの初期値\n",
    "        elif self.activation_func == \"Sigmoid\":\n",
    "            activation = Sigmoid()\n",
    "            initializer = XavierInitializer() #Xavierの初期値\n",
    "        elif self.activation_func == \"ReLU\":\n",
    "            activation = ReLU()\n",
    "            initializer = HeInitializer() #Heの初期値\n",
    "        if self.pooling == \"MaxPool2D\":\n",
    "            pooling = MaxPool2D(self.pool_h, self.pool_w, self.pool_stride, 0, self)\n",
    "        elif self.pooing == \"AveragePool2D\":\n",
    "            pooling = AveragePool2D(self.pool_h, self.pool_w, self.pool_stride, 0, self)\n",
    "        self.CNN2d1 = CNN2d(n_in_ch, self.n_filter1, self.filter_h, self.filter_w, initializer, optimizer, self)\n",
    "        self.activation1 = deepcopy(activation)\n",
    "        self.pooling1 = deepcopy(pooling)\n",
    "        self.CNN2d2 = CNN2d(self.n_filter1, self.n_filter2, self.filter_h, self.filter_w, initializer, optimizer, self)\n",
    "        self.activation2 = deepcopy(activation)\n",
    "        self.pooling2 = deepcopy(pooling)\n",
    "        self.Flatten = Flatten()\n",
    "        self.FC3 = FC(n_out_h2_p*n_out_w2_p*self.n_filter2, self.n_node3, initializer, optimizer, self)\n",
    "        self.activation3 =  ReLU()\n",
    "        self.FC4 = FC(self.n_node3, self.n_node4, initializer, optimizer, self)\n",
    "        self.activation4 =  ReLU()\n",
    "        self.FC5 = FC(self.n_node4, n_output, initializer, optimizer, self)\n",
    "        self.activation5 = Softmax()\n",
    "         \n",
    "        #fitを再帰させて学習データと検証データの両方を学習させる。検証データがあれば先に検証データを学習させる\n",
    "        if X_val is None:\n",
    "            get_mini_batch = GetMiniBatch(X, y, self.batch_size) #GetMiniBatchクラスでミニバッチを作成\n",
    "        else:\n",
    "            get_mini_batch = GetMiniBatch(X_val, y_val, self.batch_size) #GetMiniBatchクラスでミニバッチを作成\n",
    "        \n",
    "        #学習処理\n",
    "        for i in range(self.n_epoch):\n",
    "            loss_list = []\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                # このfor文内でミニバッチが使える\n",
    "\n",
    "                #forwardの処理\n",
    "                A1 = self.CNN2d1.forward(mini_X_train)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                Z1_p = self.pooling1.forward(Z1)\n",
    "                A2 = self.CNN2d2.forward(Z1_p)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                Z2_p = self.pooling2.forward(Z2)\n",
    "                Z2_f = self.Flatten.forward(Z2_p)\n",
    "                A3 = self.FC3.forward(Z2_f)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                A4 = self.FC4.forward(Z3)\n",
    "                Z4 = self.activation4.forward(A4)\n",
    "                A5 = self.FC5.forward(Z4)\n",
    "                Z5 = self.activation5.forward(A5)\n",
    "                \n",
    "                #backwardの処理\n",
    "                dA5, loss = self.activation5.backward(Z5, mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ4 = self.FC5.backward(dA5)\n",
    "                dA4 = self.activation4.backward(dZ4)\n",
    "                dZ3 = self.FC4.backward(dA4)\n",
    "                dA3 = self.activation3.backward(dZ3)\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dZ2_f = self.Flatten.backward(dZ2)\n",
    "                dZ2_p = self.pooling2.backward(dZ2_f)\n",
    "                dA2 = self.activation2.backward(dZ2_p)\n",
    "                dZ1 = self.CNN2d2.backward(dA2)\n",
    "                dZ1_p = self.pooling1.backward(dZ1)\n",
    "                dA1 = self.activation1.backward(dZ1_p)\n",
    "                dZ0 = self.CNN2d1.backward(dA1) # dZ0は使用しない\n",
    "                \n",
    "                \"\"\"\n",
    "                Loss Curvを描くための処理\n",
    "                \"\"\"                \n",
    "                loss_list.append(loss)\n",
    "\n",
    "            \n",
    "            if X_val is None:\n",
    "                self.loss_list.append(np.mean(loss_list))\n",
    "                if self.verbose: #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_list)\n",
    "            else:\n",
    "                self.loss_list_val.append(np.mean(loss_list))\n",
    "                if self.verbose: #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(loss_list_val)\n",
    "                \n",
    "        cnt += 1\n",
    "        if cnt == 3 or X_val is None:\n",
    "            return\n",
    "        \n",
    "        return self.fit(X, y, cnt = cnt) #検証データが入力されている場合は再帰させて学習データを学習させる。\n",
    "\n",
    "    def predict(self,X):\n",
    "        A1 = self.CNN2d1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        Z1_p = self.pooling1.forward(Z1)\n",
    "        A2 = self.CNN2d2.forward(Z1_p)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        Z2_p = self.pooling2.forward(Z2)\n",
    "        Z2_f = self.Flatten.forward(Z2_p)\n",
    "        A3 = self.FC3.forward(Z2_f)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        A4 = self.FC4.forward(Z3)\n",
    "        Z4 = self.activation4.forward(A4)\n",
    "        A5 = self.FC5.forward(Z4)\n",
    "        y = self.activation5.forward(A5)\n",
    "\n",
    "        print(y)\n",
    "        \n",
    "        pred = np.argmax(y, axis=1)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2dL = Scratch2dLeNet(lr=10**-2, batch_size=20, activation_func=\"ReLU\", optimizer=\"AdaGrad\", pooling=\"MaxPool2D\", pool_h_w_stride=2,\n",
    "                            n_pad=1, stride=1, filter_h=5, filter_w=5, n_filter1=6, n_filter2=16, n_node3=120, n_node4=84, n_epoch=10, verbose = False)\n",
    "s2dL.fit(X_train, y_train_one_hot, X_val, y_val_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.68275584e-11 2.63951363e-10 7.92539028e-10 ... 9.99999930e-01\n",
      "  1.15593138e-10 1.29352446e-09]\n",
      " [2.04108202e-05 1.78590200e-04 9.99800762e-01 ... 2.38494356e-11\n",
      "  7.55438917e-10 2.02626046e-11]\n",
      " [6.80956750e-09 9.99996397e-01 5.44559608e-09 ... 1.04553002e-06\n",
      "  1.29635861e-09 4.23137018e-07]\n",
      " ...\n",
      " [1.53522740e-16 2.49817634e-13 5.81802936e-14 ... 1.63232361e-09\n",
      "  3.97069677e-13 4.80313883e-10]\n",
      " [4.51014147e-08 4.56489617e-07 1.34434435e-11 ... 2.96472766e-07\n",
      "  1.01744050e-04 7.34895084e-08]\n",
      " [6.66982186e-07 4.06211276e-09 1.55884689e-09 ... 2.85376028e-10\n",
      "  1.81167709e-07 1.83119356e-09]]\n",
      "正解率：0.97\n"
     ]
    }
   ],
   "source": [
    "#テストデータ\n",
    "pred = s2dL.predict(X_test)\n",
    "print(\"正解率：{:.2f}\".format(accuracy_score(y_test, pred)))\n",
    "# print(\"混同行列：\")\n",
    "# print(confusion_matrix(y_test, pred))\n",
    "# print(\"classification_report：\") #評価をまとめて出力するやつ\n",
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"model loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(1, len(s2dL.loss_list)+1), s2dL.loss_list, label=\"train_loss\", marker=\"o\", linewidth=3)\n",
    "plt.plot(np.arange(1, len(s2dL.loss_list_val)+1), s2dL.loss_list_val, label=\"val_loss\", marker=\"o\", linewidth=3)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】（アドバンス課題）有名な画像認識モデルの調査\n",
    "CNNの代表的な構造としてはAlexNet(2012)、VGG16(2014)などがあります。こういったものはフレームワークで既に用意されていることも多いです。\n",
    "\n",
    "どういったものがあるか簡単に調べてまとめてください。名前だけでも見ておくと良いでしょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LeNet<br>\n",
    "1998年に提案された、現Facebook AI ResearchのYann LeCun先生によるCNNの元祖となるネットワーク。畳込み層とプーリング層を交互に重ねたネットワークで、この時点ですでに現在使われているアーキテクチャとほぼ同じ形になっている。活性化関数がシグモイド関数な点、プーリング層がMaxプーリングではなくサブサンプリングで縮小している点などが特徴。\n",
    "\n",
    "- AlexNet<br>\n",
    "LeNetが登場してから14年ほど経った2012年に発表された、トロント大のHinton教授を含むチームによるネットワーク。ImageNetを使った画像認識コンペILSVRCで圧倒的な成績を残し、ディープラーニングの火付け役となった。\n",
    "畳み込み層とプーリング層、そして正規化層と呼ばれる局所的正規化(LRN ― Local Response Normalization)を行う層を重ねた14層のネットワーク。活性化関数はReLUで、Dropoutを用いているのが特徴。他にもData Augmentationなども行っていて、現在使われているCNNでの主要な手法がこの時点ですでに活用されている。\n",
    "当時はGPU一台にネットワークのすべてのパラメータ(重みなど)を乗せることができなかったので、パラメータを半分にした同一構造のネットワークを2つのGPUに乗せて学習させ、最後に結合していたとか。\n",
    "\n",
    "- VGG<br>\n",
    "2014年のILSVRCで2位になった、オックスフォード大学のVGGチームのネットワーク。AlexNetをより深くした、畳み込み層とプーリング層から成るどノーマルなCNNで、重みがある層(畳み込み層や全結合層)を16層、もしくは19層重ねたもの。それぞれVGG16やVGG19と呼ばれる。\n",
    "小さいフィルターを持つ畳み込み層を2〜4つ連続して重ね、それをプーリング層でサイズを半分にするというのを繰り返し行う構造が特徴。大きいフィルターで画像を一気に畳み込むよりも小さいフィルターを何個も畳み込む(=層を深くする)方が特徴をより良く抽出できる模様。(理由はよくわかってないが、活性化関数を通る回数が増えるため、表現力が増す？)\n",
    "コンペでは2位に終わったが(1位は後述のGoogLeNet)、とてもシンプルなアーキテクチャなのでよく使われる。\n",
    "\n",
    "- GoogLeNet<br>\n",
    "2014年のコンペで1位になったアーキテクチャ。このアーキテクチャは通常の入力層から出力層まで縦一直線な構造ではなく、インセプション構造と呼ばれる横にも層が広がる構造をしている。このため、Inceptionモデルとも呼ばれる。横への層の広がりは、異なるサイズのフィルターの畳み込み層を複数横に並べて、それを結合するという形になっている。\n",
    "\n",
    "- ResNet<br>\n",
    "MicrosoftのKaiming He氏による、2015年のILSVRCで優勝したネットワーク。それまでのネットワークでは層を深くしすぎると性能が落ちるという問題があったが、それを「スキップ構造」によって解決し、152層もの深さ(前年優勝のGoogLeNetでも22層)を実現した。\n",
    "スキップ構造は、ある層への入力をバイパスし層をまたいで奥の層へ入力してしまうというもので、これにより勾配の消失や発散を防止し、超多層のネットワークを実現している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題9】出力サイズとパラメータ数の計算\n",
    "CNNモデルを構築する際には、全結合層に入力する段階で特徴量がいくつになっているかを事前に計算する必要があります。\n",
    "\n",
    "\n",
    "また、巨大なモデルを扱うようになると、メモリや計算速度の関係でパラメータ数の計算は必須になってきます。フレームワークでは各層のパラメータ数を表示させることが可能ですが、意味を理解していなくては適切な調整が行えません。\n",
    "\n",
    "\n",
    "以下の3つの畳み込み層の出力サイズとパラメータ数を計算してください。パラメータ数についてはバイアス項も考えてください。\n",
    "\n",
    "\n",
    "1.\n",
    "- 入力サイズ : 144×144, 3チャンネル\n",
    "- フィルタサイズ : 3×3, 6チャンネル\n",
    "- ストライド : 1\n",
    "- パディング : なし\n",
    "\n",
    "出力サイズ：142×142, 6チャンネル<br>\n",
    "パラメータ数：3×3×3×6 + 6 = 168<br>\n",
    "\n",
    "\n",
    "2.\n",
    "- 入力サイズ : 60×60, 24チャンネル\n",
    "- フィルタサイズ : 3×3, 48チャンネル\n",
    "- ストライド　: 1\n",
    "- パディング : なし\n",
    "\n",
    "出力サイズ：58×58, 48チャンネル<br>\n",
    "パラメータ数：24×3×3×48 + 48 = 10416<br>\n",
    "\n",
    "\n",
    "3.\n",
    "- 入力サイズ : 20×20, 10チャンネル\n",
    "- フィルタサイズ: 3×3, 20チャンネル\n",
    "- ストライド : 2\n",
    "- パディング : なし\n",
    "\n",
    "出力サイズ：9×9, 20チャンネル<br>\n",
    "パラメータ数：10×3×3×20 + 20 = 1820<br>\n",
    "\n",
    "\n",
    "＊最後の例は丁度良く畳み込みをすることができない場合です。フレームワークでは余ったピクセルを見ないという処理が行われることがあるので、その場合を考えて計算してください。端が欠けてしまうので、こういった設定は好ましくないという例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題10】（アドバンス課題）フィルタサイズに関する調査\n",
    "畳み込み層にはフィルタサイズというハイパーパラメータがありますが、2次元畳み込み層において現在では3×3と1×1の使用が大半です。以下のそれぞれを調べたり、自分なりに考えて説明してください。\n",
    "\n",
    "- 7×7などの大きめのものではなく、3×3のフィルタが一般的に使われる理由\n",
    "- 高さや幅方向を持たない1×1のフィルタの効果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7×7などの大きめのものではなく、3×3のフィルタが一般的に使われる理由\n",
    "畳み込み層では画像の特徴抽出を目的とするが、大きいフィルタサイズでは大まかな特徴の抽出しか出来ず、精度が出ないことが考えられる為。\n",
    "\n",
    "[参考資料](https://towardsdatascience.com/deciding-optimal-filter-size-for-cnns-d6f7b56f9363)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 高さや幅方向を持たない1×1のフィルタの効果\n",
    "① 次元削減(=モデルの高速化、軽量化）<br>\n",
    "② 出力にrelu等を与えることで非線形性UPができる。<br>\n",
    "\n",
    "解説：<br>\n",
    "例えば、(縦, 横, チャンネル)=(100, 100, 32)の層を、3×3の畳み込み層を用いて(100,100,64)にすることを考えます。ストレートに畳み込み層を実装すると、必要な変数は32×3×3×64+64=18496個です。次に、この2つの層の間に1×1の畳み込み層を挟んだ場合、1×1畳み込み層の出力チャンネルは32の半分の16とすると、必要な変数は、最初の畳み込み層:32×1×1×16+16=528、次の畳み込み層:16×3×3×64+64=9280、計：9808　となり、層の数は増えているにもかかわらず、元の構造からパラメータの数を半分近くまで落とすことができる。\n",
    "\n",
    "[参考資料](https://medium.com/lsc-psd/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%82%A8%E3%83%B3%E3%82%B8%E3%83%8B%E3%82%A2%E3%81%AA%E3%82%89%E7%AD%94%E3%81%88%E3%82%89%E3%82%8C%E3%81%A6%E5%BD%93%E7%84%B6%E3%81%AE4%E3%81%A4%E3%81%AE%E5%95%8F%E9%A1%8C-%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E5%B1%A4%E7%B7%A8-659809195d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
